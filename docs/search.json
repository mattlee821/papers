[
  {
    "objectID": "statistics.html",
    "href": "statistics.html",
    "title": "statistics",
    "section": "",
    "text": "Glossary of terms\nImproving Your Statistical Inferences\n\n\n\nLarge-scale composite hypothesis testing procedure for omics data analyses\n\nNovel method (qch_copula) for testing composite hypotheses across multiple traits/omics levels using mixture models with copula functions\nControls Type I error effectively while achieving superior detection power compared to 8 state-of-the-art methods across diverse correlation scenarios\nMemory-efficient implementation enables analysis of 105-106 markers with up to 20 traits, validated through psychiatric disorder pleiotropy and plant virus resistance studies\n\n\n\nSifting the evidence—what’s wrong with significance tests?\n\nCore Critique: This classic commentary criticizes the widespread misuse and over-reliance on statistical significance tests (p-values) in medical literature, arguing that this practice fundamentally distorts evidence.\nCentral Problem: The authors identify publication bias (accentuating positive results over null results) as the key factor causing the mistaken publication of chance findings as real effects, thereby eroding confidence in science.\nRecommendation: Researchers should shift their focus from the binary question of whether P &lt; 0.05 to assessing the direction and the magnitude of the effect, specifically asking if the effect is of public health or clinical importance.\n\n\n\nStatistical tests, P values, confidence intervals, and power: a guide to misinterpretations\n\nCore Principle: This influential essay details the pervasive misinterpretations and abuse of fundamental statistics—P-values, Confidence Intervals (CIs), and statistical power—in scientific literature.\nP-value Clarification: The authors correct 12 common misconceptions, asserting that the P-value is not the probability of the null hypothesis (\\(H_0\\)) being true, but rather the probability of the observed data (or more extreme) given that \\(H_0\\) is true.\nMisuse of Significance: The essay strongly condemns the practice of drawing dichotomous conclusions based on an arbitrary threshold (e.g., P&lt;0.05), which falsely implies certainty and hinders scientific progress.\nRecommendation: Researchers are urged to shift focus from the P-value to the effect magnitude and its precision, which are better conveyed through Confidence Intervals, and to integrate statistical results with contextual, external evidence.\n\n\n\nThe ASA’s Statement on p-Values: Context, Process, and Purpose\n\nCore Principle: This article presents the American Statistical Association’s (ASA) six core principles for the proper use of the P-value, aiming to correct pervasive misinterpretations in scientific research.\nKey Principles: The ASA states that the P-value does not measure the probability that a hypothesis is true (Principle 2) or the size/importance of an effect (Principle 5). Instead, it measures how incompatible the data are with a statistical model (Principle 1).\nCrucial Admonitions: The statement strongly advises against drawing dichotomous conclusions based solely on a fixed threshold (e.g., P&lt;0.05, Principle 3) and requires full reporting and transparency of all results to combat selective reporting (Principle 4).\nRecommendation: The ASA advocates for a move beyond the single P-value to integrate statistical results with effect sizes, Confidence Intervals, context, and external evidence (Principle 6).\n\n\n\nTriangulation in aetiological epidemiology: Approaches to causal inference\n\nCore Principle: This article formally advocates for Triangulation in aetiological epidemiology, defined as the integration of results from multiple research approaches where each approach possesses uncorrelated sources of bias.\nCausal Inference: If different methods (e.g., observational studies, Mendelian Randomization, and clinical trials) all converge on the same causal conclusion, confidence in that finding is significantly strengthened, especially when method-specific biases would predict opposing results.\nAddressing Inconsistency: When results are inconsistent, the framework helps identify which source of bias (e.g., confounding, reverse causation) is most likely distorting a given approach, thereby guiding the direction of future, more focused research.\n\n\n\nCausal Inference Is Not Just a Statistics Problem\n\nCore Argument: This article argues that causal inference relies primarily on study design and domain knowledge to establish untestable assumptions (like exchangeability and no unmeasured confounding), with statistical methods serving only to quantify the effect under those assumptions.\nDesign Trumps Analysis: The authors emphasize that a causal estimate is invalid if the study design fails to account for critical (especially unmeasured) confounders, regardless of the sophistication of the statistical modeling used.\nThe Role of Causal Diagrams: Identifying which variables to control is a causal question, not a statistical one, necessitating the use of Directed Acyclic Graphs (DAGs) and scientific expertise to avoid introducing bias by controlling for mediators or colliders.\nConclusion: Teaching and practicing causal inference requires prioritizing the formulation of a causal question and the design of the study before the application of statistical tools.\n\n\n\nMoving to a World Beyond \\(p &lt; 0.05\\)\n\nCore Argument: This editorial calls for the abandonment of the term “statistically significant” and the practice of dichotomizing results based on the arbitrary \\(p &lt; 0.05\\) threshold.\nCentral Problem: Relying on the binary threshold distorts evidence, fuels poor practices like P-hacking and publication bias, and leads to the false equating of statistical significance with scientific importance.\nRecommendation: Researchers must treat the p-value as a continuous measure of incompatibility between the data and the null hypothesis. They should focus their interpretation on the magnitude of the effect and its precision, primarily communicated via Confidence Intervals (CIs).\n\n\n\nTesting For Baseline Balance In Clinical Trials\n\nCore Principle: This paper argues that performing tests of baseline homogeneity (p-value tests) in randomized controlled trials (RCTs) is philosophically unsound, of no practical value, and potentially misleading, as randomization ensures comparability in expectation.\nThe Flaw: A non-significant baseline difference does not prove balance (it reflects low power), and a significant difference is merely a chance event that does not invalidate the randomization.\nRecommendation: The authors recommend that researchers must abandon baseline testing and, instead, identify known prognostic variables in the trial-plan and fit them in an Analysis of Covariance (ANCOVA) model regardless of their baseline p-value, which increases the precision and power of the final treatment effect estimate.\n\n\n\nCovariate Imbalance and Adjustment for Logistic Regression Analysis of Clinical Trial Data\n\nCore Problem: This study demonstrates that, for binary outcomes analyzed with logistic regression, the unadjusted Odds Ratio (OR) is generally a biased estimate of the conditional OR due to the non-collapsibility of the OR, even in a perfectly randomized trial.\nKey Finding: Adjusting for prognostic covariates in logistic regression is critical, as it significantly increases statistical power (by up to 17.5% in simulations) and reduces bias in the treatment effect estimate.\nRecommendation: While good baseline balance in covariates is desirable, it never fully alleviates the shortcomings of unadjusted analyses in the logistic setting; researchers should pre-specify and use covariate adjustment for prognostic variables to ensure the most precise and efficient estimate.\n\n\n\nStep away from stepwise\n\nCore Argument: This report critiques stepwise regression, arguing it is a flawed statistical method, especially in the context of Big Data, because it uses statistical significance to select variables.\nKey Flaw: Stepwise procedures may include nuisance variables that are coincidentally significant and exclude true explanatory variables that happen to be non-significant, leading to models that fit data well in-sample but perform poorly out-of-sample.\nBig Data Effect: The belief that stepwise is more useful with more variables is false; Big Data exacerbates its failings by increasing the chance of selecting spurious correlations, causing a dramatic deterioration in out-of-sample predictive accuracy.\n\n\n\nThe Abuse of Power: The Pervasive Fallacy of Power Calculations for Data Analysis\n\nCore Argument: This paper argues that retrospective power calculations (or observed power), performed after a study yields a non-significant result, are fundamentally flawed and should not be used to aid in interpretation.\nThe Flaw (Circularity): Retrospective power is a simple monotonic transformation of the p-value; it provides no new information. A non-significant test will always have low retrospective power, as both measures are driven by the large variance or small observed effect.\nRecommended Alternative: To interpret a non-significant finding, researchers should focus on the confidence interval, which reveals the range of plausible true effect sizes and indicates whether biologically or clinically important effects have been reasonably ruled out.\n\n\n\nThe cost of dichotomising continuous variables\n\nAvoidable Costs: The practice of dichotomizing continuous variables for statistical analysis leads to a substantial loss of statistical power and an inflation of the Type I error rate (false positives) in multivariable models.\nFlawed Interpretation: Dichotomization uses arbitrary or unstable cut-points, provides misleading effect estimates, and ignores the true shape of the relationship across the continuous scale.\nRecommendation: Continuous variables should be analyzed on their original scale (or using methods like fractional polynomials/splines) to preserve information and avoid these serious statistical drawbacks.\n\n\n\nSpurious interaction as a result of categorization\n\nCore Argument: Categorizing continuous exposure variables in regression models, a common practice in epidemiology, can introduce spurious interaction effects that do not exist in the original continuous scale.\nMechanism: This phenomenon is demonstrated analytically and is interpreted as a form of differential measurement error or residual confounding caused by the categorization process.\nConclusion: Spurious interaction is induced unless the correlated variables are dichotomized at the median or are uncorrelated. The paper strongly recommends avoiding categorization to ensure valid results, suggesting non-parametric models as a preferred alternative.\n\n\n\nSynthesizing Subject-matter Expertise for Variable Selection in Causal Effect Estimation: A Case Study\n\nObjective: To empirically assess different strategies for Directed Acyclic Graph (DAG) creation and the resulting minimal adjustment sets for estimating a known causal effect (adherence on mortality in the CDP trial).\nKey Finding (Efficiency): The results confirm that including nonconfounding prognostic factors (outcome predictors) significantly reduced variance (increased efficiency) of the causal effect estimate, aligning with theoretical statistical advice.\nRecommendation: Researchers should prioritize the exhaustive identification of all potential outcome prognostic factors as the initial and most crucial step when constructing DAGs for causal effect estimation.\n\n\n\nCan algorithms replace expert knowledge for causal inference? A case study on novice use of causal discovery\n\nObjective: To test whether causal discovery algorithms used by novices could replace expert knowledge in selecting covariates for estimating the known null effect of placebo adherence on mortality in the CDP trial.\nKey Finding: Adjustment sets derived from causal discovery algorithms resulted in more residual bias in complex time-varying analyses compared to expert-selected sets.\nConclusion: Due to high subjectivity in selecting algorithms/parameters and resolving complex graph outputs, the authors do not recommend novice use of causal discovery without an expert’s guidance.\n\n\n\nA Structural Description of Biases That Generate Immortal Time\n\nCore Argument: The true source of immortal time bias is the underlying selection or misclassification of subjects, not the period of event-free time itself.\nTwo Mechanisms: The paper structurally describes two ways the bias arises: 1) Selection bias when eligibility is applied after assignment; and 2) Misclassification bias when assignment is defined using post-eligibility data for strategies indistinguishable at baseline.\nPrevention: The definitive solution is to use Target Trial Emulation to achieve synchronization of eligibility and treatment assignment at the start of follow-up, thereby eliminating the generating biases."
  },
  {
    "objectID": "genetics/monsees_2009_19365863.html",
    "href": "genetics/monsees_2009_19365863.html",
    "title": "Genome-wide association scans for secondary traits using case-control samples",
    "section": "",
    "text": "PubMed: 19365863\nDOI: 10.1002/gepi.20424\nOverview generated by: Gemini 2.5 Flash, 26/11/2025"
  },
  {
    "objectID": "genetics/monsees_2009_19365863.html#key-findings",
    "href": "genetics/monsees_2009_19365863.html#key-findings",
    "title": "Genome-wide association scans for secondary traits using case-control samples",
    "section": "Key Findings",
    "text": "Key Findings\nThis paper addresses a critical methodological issue in genetic epidemiology where researchers attempt to maximize the return on investment from an expensive case-control Genome-Wide Association Study (GWAS) by analyzing additional, or secondary, quantitative traits (e.g., body mass index, mammographic density) collected on the same subjects. The core finding is that a naïve analysis (ignoring the case-control ascertainment) can lead to biased estimates of the association between a genetic marker and the secondary trait, particularly when both the marker and the secondary trait are independently associated with the primary disease risk. The authors demonstrate that the use of Inverse-Probability-of-Sampling-Weighted (IPW) regression provides unbiased estimates of the marker-secondary trait association in all scenarios, although it may suffer from reduced statistical power compared to the biased naïve methods."
  },
  {
    "objectID": "genetics/monsees_2009_19365863.html#statistical-problem-ascertainment-bias",
    "href": "genetics/monsees_2009_19365863.html#statistical-problem-ascertainment-bias",
    "title": "Genome-wide association scans for secondary traits using case-control samples",
    "section": "Statistical Problem: Ascertainment Bias",
    "text": "Statistical Problem: Ascertainment Bias\nCase-control studies are designed to test the association between a genetic marker and a primary binary disease (e.g., breast cancer). When using these same samples to study a quantitative trait (the secondary trait, e.g., mammographic density), the selection process (ascertainment) based on the disease status introduces a bias.\n\nNaïve Analysis Scenarios\nThe study mathematically and via simulation tested the performance of two “naïve” approaches for testing the association between a marker (\\(G\\)) and a secondary trait (\\(T\\)) using case-control data, where \\(D\\) is the primary disease status:\n\nIgnoring \\(D\\): Regressing \\(T\\) on \\(G\\) in the combined sample, ignoring case-control status.\nStratifying on \\(D\\): Regressing \\(T\\) on \\(G\\) separately within cases and controls, and then combining the results (e.g., via meta-analysis).\n\nThe paper shows that both naïve methods have:\n\nProper Type I Error Rates (Unbiased Test): When testing the null hypothesis of no \\(G-T\\) association, the methods maintain the correct Type I error rate unless both \\(G\\) and \\(T\\) are independently associated with the primary disease \\(D\\).\nUnbiased Estimates (Under Alternative): Under the alternative hypothesis (i.e., a true \\(G-T\\) association exists), the estimated effect size is unbiased only if the secondary trait \\(T\\) is not associated with the primary disease \\(D\\).\n\n\n\nSource of Bias\nThe bias in the naïve methods occurs when a significant confounding pathway exists: \\(G \\rightarrow D \\leftarrow T\\). Since the case-control study non-randomly samples based on \\(D\\), this selection distorts the observed association between \\(G\\) and \\(T\\)."
  },
  {
    "objectID": "genetics/monsees_2009_19365863.html#solution-inverse-probability-of-sampling-weighting-ipw",
    "href": "genetics/monsees_2009_19365863.html#solution-inverse-probability-of-sampling-weighting-ipw",
    "title": "Genome-wide association scans for secondary traits using case-control samples",
    "section": "Solution: Inverse-Probability-of-Sampling Weighting (IPW)",
    "text": "Solution: Inverse-Probability-of-Sampling Weighting (IPW)\nThe authors propose using IPW regression to correct for the ascertainment bias. IPW uses weights in the regression calculation that are inversely proportional to the probability of an individual being sampled into the study.\n\nThe weights are calculated based on the sampling fractions of cases and controls.\nPerformance: IPW regression yielded unbiased estimates of the \\(G-T\\) association and maintained the proper Type I error rate in all scenarios considered, regardless of the association between \\(G\\), \\(T\\), and \\(D\\).\nTrade-off: IPW regression consistently demonstrated lower statistical power than the naïve analyses in situations where the naïve analyses were also unbiased."
  },
  {
    "objectID": "genetics/monsees_2009_19365863.html#practical-recommendations",
    "href": "genetics/monsees_2009_19365863.html#practical-recommendations",
    "title": "Genome-wide association scans for secondary traits using case-control samples",
    "section": "Practical Recommendations",
    "text": "Practical Recommendations\nThe study concludes with practical recommendations for GWAS analysis of secondary traits:\n\nGeneral Markers: For the vast majority of markers tested in a GWAS (which are not associated with the primary disease \\(D\\)), the naïve analyses are valid tests of association and provide nearly unbiased estimates of the \\(G-T\\) association.\nDisease-Associated Markers: Care must be taken when both the marker (\\(G\\)) and the secondary trait (\\(T\\)) are associated with the primary disease (\\(D\\)). In this scenario, the naïve estimates will be biased, and IPW regression is the statistically valid method to obtain an unbiased estimate of the \\(G-T\\) effect.\nIllustration: The authors illustrate the potential for bias using an analysis of the relationship between a marker in the FGFR2 gene (a known breast cancer risk locus) and mammographic density in a breast cancer case-control sample."
  },
  {
    "objectID": "genetics/aschard_2015_25640676.html",
    "href": "genetics/aschard_2015_25640676.html",
    "title": "Adjusting for Heritable Covariates Can Bias Effect Estimates in Genome-Wide Association Studies",
    "section": "",
    "text": "PubMed: 25640676\nDOI: 10.1016/j.ajhg.2014.12.021\nOverview generated by: Gemini 2.5 Flash, 26/11/2025"
  },
  {
    "objectID": "genetics/aschard_2015_25640676.html#key-findings",
    "href": "genetics/aschard_2015_25640676.html#key-findings",
    "title": "Adjusting for Heritable Covariates Can Bias Effect Estimates in Genome-Wide Association Studies",
    "section": "Key Findings",
    "text": "Key Findings\nThis seminal methodological report examines the statistical consequences of adjusting Genome-Wide Association Studies (GWAS) for heritable covariates (correlated traits that are themselves genetically influenced), conclusively demonstrating that this common practice introduces a significant collider bias.\n\nMain Discoveries\n\nCollider Bias Introduction: Adjusting a standard GWAS regression for a heritable covariate (\\(C\\)) that is correlated with the outcome (\\(Y\\)) and influenced by the SNP (\\(G\\)) introduces bias (also known as index event bias or selection bias). This happens because conditioning on the covariate (the collider) opens a spurious path between the SNP and unobserved confounders, which can lead to false positive associations with the primary outcome.\nUnbiased Estimation Condition: The resulting adjusted effect, \\(\\beta_{G \\rightarrow Y \\mid C}\\), accurately estimates the direct genetic effect on the outcome only under two strict causal models:\n\nThe SNP has no effect on the covariate (\\(\\beta_{G \\rightarrow C} = 0\\)).\nThe covariate (\\(C\\)) is a pure mediator, where the correlation between \\(C\\) and \\(Y\\) is entirely explained by a direct causal effect of \\(C\\) on \\(Y\\).\n\nBias Formula: For scenarios involving shared genetic or environmental risk factors, the bias (\\(\\text{Bias}\\)) in the adjusted genetic effect estimate is well-approximated by the equation: \\[\\text{Bias} \\approx -\\beta_{G \\rightarrow C} \\cdot \\rho_{C Y} \\cdot \\sqrt{\\frac{\\text{Var}(C)}{\\text{Var}(Y)}}\\] Where \\(\\beta_{G \\rightarrow C}\\) is the genetic effect on the covariate, and \\(\\rho_{C Y}\\) is the phenotypic correlation between the covariate and the outcome. The magnitude and direction of the bias are dependent on these terms."
  },
  {
    "objectID": "genetics/aschard_2015_25640676.html#study-design",
    "href": "genetics/aschard_2015_25640676.html#study-design",
    "title": "Adjusting for Heritable Covariates Can Bias Effect Estimates in Genome-Wide Association Studies",
    "section": "Study Design",
    "text": "Study Design\nThe study employed a rigorous statistical approach using established causal inference frameworks, detailed theoretical modeling, and numerical simulations.\n\nTheoretical Framework\n\nModeling of the True Direct Effect: The study defined the desired quantity, the direct genetic effect \\(\\beta_{G \\rightarrow Y}\\), as the effect of the SNP (\\(G\\)) on the outcome (\\(Y\\)) independent of the covariate (\\(C\\)). This is achieved by adjusting for all causal factors of the covariate.\nLinear Regression Model: The estimation was performed using a standard linear regression: \\(Y = \\alpha + \\beta_{G \\rightarrow Y \\mid C} G + \\gamma C + \\epsilon\\). The authors derived the expected value of the adjusted coefficient, \\(\\mathbb{E}[\\beta_{G \\rightarrow Y \\mid C}]\\), showing that it equals the true direct effect plus the bias term under various causal scenarios.\nBias Derivation: The bias was derived by considering the correlation structure induced when the covariate and the outcome share unobserved causes, specifically showing how adjustment for \\(C\\) introduces conditioning on a collider related to the SNP’s effect. The full mathematical expression for the bias was derived, from which the simplified approximation was obtained.\n\n\n\nSimulation Methods\n\nScenarios Tested: Simulations covered all three major causal scenarios: C is a mediator of the effect of \\(G\\) on \\(Y\\); Y is a mediator of the effect of \\(G\\) on \\(C\\); and \\(G\\) is a shared cause (pleiotropy) where the effect of \\(G\\) on \\(Y\\) is mediated by \\(C\\), or the traits share a hidden common environmental cause (\\(U\\)).\nParameters: Simulations varied key parameters, including heritability of the traits (up to \\(h^2 = 0.5\\)), the phenotypic correlation (\\(\\rho_{C Y}\\), up to \\(0.5\\)), and the genetic effect sizes (\\(\\beta_G\\)).\nEvaluation Metrics: The primary metrics used to evaluate the consequences of the bias were the Type I error rate (false positive rate) and the statistical power of the adjusted association test. Results showed Type I error inflation when the adjusted model was used in biased scenarios.\n\n\n\nReal-World Data Application\n\nData Source: GWAS summary statistics from the GIANT consortium meta-analysis of anthropometric traits were used, specifically:\n\nGWAS of Waist-to-Hip Ratio (WHR) adjusted for BMI (\\(Y \\mid C\\)).\nGWAS of BMI (\\(C\\)).\n\nEmpirical Test: A test was performed to look for an enrichment of SNPs with marginal effects in opposite directions on WHR and BMI. A highly significant enrichment (\\(p=0.005\\)) was found, providing empirical evidence that the statistical bias was present and inflating the number of significant loci."
  },
  {
    "objectID": "genetics/aschard_2015_25640676.html#major-results",
    "href": "genetics/aschard_2015_25640676.html#major-results",
    "title": "Adjusting for Heritable Covariates Can Bias Effect Estimates in Genome-Wide Association Studies",
    "section": "Major Results",
    "text": "Major Results\n\nPower Paradox: Adjustment for a heritable covariate results in increased statistical power when the signs of \\(\\beta_{G \\rightarrow Y \\mid C}\\) and the bias term are in opposite directions. This effect explains the increased detection of specific loci in the WHR adjusted for BMI GWAS.\nInterpretation Challenge: Since the adjusted estimates reflect a combination of the true direct effect and the bias term, they are neither the total genetic effect nor the direct genetic effect in most scenarios involving shared genetic or environmental risk factors.\nRelevance to Ratio Traits: The findings are directly relevant to analyses of ratio traits (e.g., WHR, fasting glucose/insulin ratios), as these are mathematically equivalent to performing a regression adjusted for the denominator."
  },
  {
    "objectID": "genetics/aschard_2015_25640676.html#practical-implications",
    "href": "genetics/aschard_2015_25640676.html#practical-implications",
    "title": "Adjusting for Heritable Covariates Can Bias Effect Estimates in Genome-Wide Association Studies",
    "section": "Practical Implications",
    "text": "Practical Implications\n\nRecommendations for Future GWAS\n\nPrioritize Unadjusted Analysis: For general genetic discovery and estimation of the total genetic effect (which includes effects mediated through other traits), the unadjusted GWAS of the primary outcome is the statistically unbiased standard.\nUse Bivariate Methods: To gain statistical power and accurately account for correlated traits without introducing collider bias, researchers should prefer multivariate or bivariate methods (e.g., those simultaneously modeling both \\(C\\) and \\(Y\\)) over simple regression adjustment.\nCausal Inference: If the research goal is specifically to estimate the direct causal effect, more advanced methods like Multivariable Mendelian Randomization (MVMR) should be considered to isolate the effect while mitigating the bias."
  },
  {
    "objectID": "genetics/aschard_2015_25640676.html#related-concepts",
    "href": "genetics/aschard_2015_25640676.html#related-concepts",
    "title": "Adjusting for Heritable Covariates Can Bias Effect Estimates in Genome-Wide Association Studies",
    "section": "Related Concepts",
    "text": "Related Concepts\n\nCollider Bias: A form of selection bias where conditioning on a variable that is a common effect (a collider) of two other variables induces a spurious association between the two causes.\nDirect vs. Total Genetic Effect: The direct effect is the association independent of the covariate; the total effect includes the portion mediated through the covariate.\nWaist-to-Hip Ratio (WHR) adjusted for BMI: The primary empirical example, where the adjustment for the highly heritable BMI creates a biased estimate for the remaining variance of WHR."
  },
  {
    "objectID": "genetics/spence_2025_41193809.html",
    "href": "genetics/spence_2025_41193809.html",
    "title": "Specificity, length and luck drive gene rankings in association studies",
    "section": "",
    "text": "PubMed: 41193809\nDOI: 10.1038/s41586-025-09703-7\nOverview generated by: Claude Sonnet 4.5, 25/11/2025"
  },
  {
    "objectID": "genetics/spence_2025_41193809.html#key-findings",
    "href": "genetics/spence_2025_41193809.html#key-findings",
    "title": "Specificity, length and luck drive gene rankings in association studies",
    "section": "Key Findings",
    "text": "Key Findings\nThis study provides a systematic comparison of genome-wide association studies (GWAS) and rare variant loss-of-function (LoF) burden tests, revealing fundamental differences in how these methods prioritize genes.\n\nMain Discoveries\n\nDifferent Gene Rankings: GWAS and LoF burden tests systematically prioritize different genes, even when accounting for power differences and gene-mapping issues\nTrait Specificity vs. Importance:\n\nBurden tests prioritize trait-specific genes (genes primarily affecting the studied trait)\nGWAS prioritize trait-specific variants (which can act on pleiotropic genes through context-specific effects)\n\nThree Key Factors:\n\nSpecificity: How specific a gene/variant’s effects are to the trait under study\nLength: Longer genes are more likely to be discovered by burden tests due to more LoF sites\nLuck: Random genetic drift causes variant frequencies to vary, making GWAS rankings partially stochastic"
  },
  {
    "objectID": "genetics/spence_2025_41193809.html#study-design",
    "href": "genetics/spence_2025_41193809.html#study-design",
    "title": "Specificity, length and luck drive gene rankings in association studies",
    "section": "Study Design",
    "text": "Study Design\n\nData Source\n\n209 quantitative traits from UK Biobank\nAnalyzed both GWAS and LoF burden test results\n~360,000 individuals for GWAS\n~450,000 individuals for burden tests\n\n\n\nAnalytical Framework\nThe authors proposed two criteria for gene prioritization:\n\nTrait Importance: How much a gene quantitatively affects a trait (effect size)\nTrait Specificity: The importance of a gene for the studied trait relative to all other traits"
  },
  {
    "objectID": "genetics/spence_2025_41193809.html#major-results",
    "href": "genetics/spence_2025_41193809.html#major-results",
    "title": "Specificity, length and luck drive gene rankings in association studies",
    "section": "Major Results",
    "text": "Major Results\n\n1. Discordant Gene Rankings\n\nOnly 26% of burden test hits fall within top GWAS loci\n74.6% of burden hits are within any GWAS locus, but often ranked much lower\nExample: NPR2 is the 2nd most significant burden test gene for height but contained in the 243rd most significant GWAS locus\n\n\n\n2. Why Burden Tests Prioritize Trait-Specific Genes\nBurden tests aggregate LoF variants within genes. The expected association strength is proportional to:\n\\[\\frac{\\gamma_1^2}{\\sum_t \\gamma_t^2}\\]\nwhere \\(\\gamma_1^2\\) is the gene’s effect on the studied trait and \\(\\sum_t \\gamma_t^2\\) is its total effect across all traits.\nKey mechanisms: - Natural selection acts more strongly on genes with larger total effects across traits - This keeps LoF frequencies lower for pleiotropic genes - Result: Trait-specific genes have more power in burden tests despite potentially smaller effects\n\n\n3. Why GWAS Capture Pleiotropic Genes\nGWAS prioritize trait-specific variants, which can arise in two ways:\n\nVariants affecting trait-specific genes\nContext-specific variants on pleiotropic genes (e.g., tissue-specific regulatory variants)\n\nThe study found: - Variants in tissue-specific ATAC peaks show higher heritability enrichment - Coding variants in specifically expressed genes contribute more to heritability - This explains why GWAS can identify highly pleiotropic genes missed by burden tests\n\n\n4. Gene Length Bias in Burden Tests\n\nLonger genes have more potential LoF sites\nThis increases LoF carrier frequency, boosting statistical power\nEffect: Longer genes appear more significant and more pleiotropic, independent of their true biological importance\n\n\n\n5. The Role of Genetic Drift in GWAS\n\nRandom drift causes variant frequencies to vary widely around their expected values\nFor sufficiently important variants, GWAS rankings become largely random with respect to true effect size\nHigh-frequency variants have more power, creating an apparent “pleiotropy” of top GWAS hits (statistical artifact)"
  },
  {
    "objectID": "genetics/spence_2025_41193809.html#estimating-trait-importance",
    "href": "genetics/spence_2025_41193809.html#estimating-trait-importance",
    "title": "Specificity, length and luck drive gene rankings in association studies",
    "section": "Estimating Trait Importance",
    "text": "Estimating Trait Importance\nNeither method directly ranks genes by trait importance:\n\nBurden tests: Flattening effect - most important genes are most constrained, leading to smallest frequencies and largest standard errors\nGWAS: Individual variant rankings dominated by random frequency variation\n\nSolution: Aggregate signals across multiple variant types - Methods like AMM that combine evidence across many variants per gene - Better correlates with selection coefficients (proxy for importance) - Overcomes the flattening problem"
  },
  {
    "objectID": "genetics/spence_2025_41193809.html#biological-implications",
    "href": "genetics/spence_2025_41193809.html#biological-implications",
    "title": "Specificity, length and luck drive gene rankings in association studies",
    "section": "Biological Implications",
    "text": "Biological Implications\n\nContext-Specific Variants\nThe finding that many GWAS loci lack burden signals suggests context-specific variants acting on pleiotropic genes are major drivers of complex traits. The authors hypothesize these may include: - Developmental genes - Variants that perturb developmental trajectories in trait-specific ways - Tissue-specific regulatory elements\n\n\nDrug Target Discovery\n\nTrait-specific genes (identified by burden tests) may be better drug targets due to fewer side effects\nExplains why LoF burden evidence is more predictive of drug trial success than GWAS evidence\nHowever, if pleiotropic genes can be targeted context-specifically, they may have greater clinical impact"
  },
  {
    "objectID": "genetics/spence_2025_41193809.html#methodological-insights",
    "href": "genetics/spence_2025_41193809.html#methodological-insights",
    "title": "Specificity, length and luck drive gene rankings in association studies",
    "section": "Methodological Insights",
    "text": "Methodological Insights\n\nS-LDSC Analysis\nThe study used stratified LD score regression to show: - Heritability enrichment in tissue-specific ATAC peaks - Coding variants in specifically expressed genes contribute more to heritability - Both axes (gene specificity and variant context-specificity) independently contribute to GWAS signals\n\n\nPopulation Genetics Modeling\nUsed stabilizing selection models to predict: - LoF frequencies inversely proportional to selection coefficient (\\(s_{het}\\)) - Selection coefficient proportional to total trait effects across all traits - Explains observed relationship between constraint and LoF frequency"
  },
  {
    "objectID": "genetics/spence_2025_41193809.html#limitations-and-considerations",
    "href": "genetics/spence_2025_41193809.html#limitations-and-considerations",
    "title": "Specificity, length and luck drive gene rankings in association studies",
    "section": "Limitations and Considerations",
    "text": "Limitations and Considerations\n\nComplexity of gene effects: The simplified model (\\(\\alpha = \\beta \\gamma\\)) may not capture non-linear relationships\nIncomplete pleiotropy landscape: Only 27 traits analyzed, actual pleiotropy may be higher\nContext-specificity: Not all pleiotropic genes can be therapeutically targeted in context-specific ways"
  },
  {
    "objectID": "genetics/spence_2025_41193809.html#practical-recommendations",
    "href": "genetics/spence_2025_41193809.html#practical-recommendations",
    "title": "Specificity, length and luck drive gene rankings in association studies",
    "section": "Practical Recommendations",
    "text": "Practical Recommendations\n\nFor Association Study Interpretation\n\nUse both methods: GWAS and burden tests reveal complementary aspects of trait biology\nConsider gene length: Longer genes in burden test results may be artifacts\nAggregate variants: For trait importance, use methods that combine signals across variants (AMM, MAGMA)\nMind the drift: Top GWAS hits are partially determined by random frequency variation\n\n\n\nFor Drug Development\n\nBurden test hits may indicate better targets for minimizing side effects\nGWAS hits may reveal pleiotropic genes with larger phenotypic impact\nConsider whether context-specific targeting is feasible"
  },
  {
    "objectID": "genetics/spence_2025_41193809.html#conclusions",
    "href": "genetics/spence_2025_41193809.html#conclusions",
    "title": "Specificity, length and luck drive gene rankings in association studies",
    "section": "Conclusions",
    "text": "Conclusions\nGWAS and LoF burden tests systematically prioritize different genes because:\n\nBurden tests rank by gene-level trait specificity, favoring long, trait-specific genes\nGWAS rank by variant-level trait specificity, capturing both trait-specific genes and context-specific variants on pleiotropic genes\n\nNeither method directly ranks by trait importance due to: - Burden tests: Flattening from natural selection - GWAS: Random genetic drift\nBoth methods are valuable and reveal distinct aspects of trait biology. The choice of method depends on the research question and application, with burden tests better for identifying specific biology and GWAS better for comprehensive discovery including pleiotropic mechanisms."
  },
  {
    "objectID": "genetics/spence_2025_41193809.html#related-concepts",
    "href": "genetics/spence_2025_41193809.html#related-concepts",
    "title": "Specificity, length and luck drive gene rankings in association studies",
    "section": "Related Concepts",
    "text": "Related Concepts\n\nTrait specificity (\\(\\Psi_G\\)): \\(\\gamma_1^2 / \\sum_t \\gamma_t^2\\) for genes\nTrait importance: \\(\\gamma_1^2\\) (squared effect size)\nFlattening: Association strength becomes independent of effect size for highly important genes\nContext-specificity: Variants acting only in certain cellular contexts or developmental stages"
  },
  {
    "objectID": "multi-omics.html",
    "href": "multi-omics.html",
    "title": "Multi-Omics",
    "section": "",
    "text": "test\ntest"
  },
  {
    "objectID": "pgs/ding_2023_37198491.html",
    "href": "pgs/ding_2023_37198491.html",
    "title": "Polygenic scoring accuracy varies across the genetic ancestry continuum",
    "section": "",
    "text": "PubMed: 37198491 DOI: 10.1038/s41586-023-06079-4 Overview generated by: Gemini 2.5 Flash, 26/11/2025"
  },
  {
    "objectID": "pgs/ding_2023_37198491.html#key-findings-the-genetic-distance-penalty-on-pgs-accuracy",
    "href": "pgs/ding_2023_37198491.html#key-findings-the-genetic-distance-penalty-on-pgs-accuracy",
    "title": "Polygenic scoring accuracy varies across the genetic ancestry continuum",
    "section": "Key Findings: The Genetic Distance Penalty on PGS Accuracy",
    "text": "Key Findings: The Genetic Distance Penalty on PGS Accuracy\nThis study provides a critical, individual-level assessment of Polygenic Score (PGS) portability, which is necessary for the equitable clinical application of genetic risk prediction. The authors argue that assessing PGS performance using traditional discrete genetic ancestry clusters (e.g., European, African) obscures crucial inter-individual variation and biases estimates. They introduce a framework that evaluates accuracy along a genetic ancestry continuum using a precise metric: Genetic Distance (GD).\n\nCore Discovery: Continuous and Steep Decay of Accuracy\nThe central finding is the demonstration that PGS accuracy decreases individual-to-individual along the continuum of genetic ancestries in a highly predictable, linear fashion .\n\nMetric Definition: Genetic Distance (GD) is defined as the distance of a target individual’s genotype (e.g., PCA projection) from the population used to train the PGS model. The higher the GD, the more genetically dissimilar the individual is from the training set.\nQuantification of Decay: Across a large set of 84 complex traits and diseases, the average individual-level PGS accuracy showed an extremely powerful negative correlation with GD, with a Pearson correlation coefficient of -0.95. This near-perfect correlation highlights that the individual’s genetic background relative to the training population is the primary determinant of score performance.\nUbiquity of Variation: This decreasing trend was observed in all populations considered, including within traditionally labeled ‘homogeneous’ genetic ancestry groups (e.g., European ancestry in UK Biobank). This shows that sub-ancestry variation within a single continent still results in a measurable loss of accuracy based on GD.\n\n\n\nDemonstrating Inequity and Systematic Bias\nThe study leveraged data from the UK Biobank (UKBB, training set, predominantly White British) and the diverse Los Angeles biobank (ATLAS, testing set) to quantify the transferability gap.\n\nIntra-European Penalty: When applying UKBB-trained models to individuals of European ancestry in ATLAS, those in the furthest GD decile experienced a significant 14% lower accuracy relative to those in the closest decile.\nCross-Ancestry Disparity: The results reveal a severe “distance penalty” for non-European groups. Individuals of Hispanic/Latino American ancestry who are genetically closest (lowest GD decile) to the training data showed similar PGS performance to the European-ancestry individuals who are furthest away (highest GD decile). For the most distant Hispanic/Latino individuals, accuracy was substantially lower, overlapping with that of African American participants.\nBias in Risk Estimates: Crucially, GD was found to be significantly correlated with the PGS estimates themselves for 82 of 84 traits. This means the systematic bias due to ancestry distance does not just affect the accuracy (\\(R^2\\)) but also the magnitude of the predicted risk, potentially leading to widespread miscalibration and inequitable risk stratification.\n\n\n\nConclusion and Call to Action\nThe authors conclude that relying on aggregate population-level metrics (\\(\\text{e.g., } R^2\\)) obscures this vital individual-level variation and hinders efforts toward health equity. They urge researchers to abandon the use of discrete genetic ancestry clusters in favor of continuous metrics (like GD) to better characterize and address performance disparities, ensuring more reliable and equitable application of PGSs in personalized medicine."
  },
  {
    "objectID": "pgs/mars_2022_35591975.html",
    "href": "pgs/mars_2022_35591975.html",
    "title": "Genome-wide risk prediction of common diseases across ancestries in one million people",
    "section": "",
    "text": "PubMed: 35591975\nDOI: 10.1016/j.xgen.2022.100118\nOverview generated by: Gemini 2.5 Flash, 26/11/2025"
  },
  {
    "objectID": "pgs/mars_2022_35591975.html#key-findings",
    "href": "pgs/mars_2022_35591975.html#key-findings",
    "title": "Genome-wide risk prediction of common diseases across ancestries in one million people",
    "section": "Key Findings",
    "text": "Key Findings\nThis study performed a large-scale, cross-ancestry evaluation of Polygenic Risk Scores (PRSs) for four major common diseases—Coronary Artery Disease (CAD), Type 2 Diabetes (T2D), Breast Cancer, and Prostate Cancer—using genome-wide genotype data from six biobanks across Europe, the United States, and Asia, encompassing over one million individuals. The principal finding is a striking disparity in PRS transferability and accuracy: the predictive ability of PRSs remains robust and highly similar across various European populations and local population substructures, suggesting utility in clinical settings for this group. However, the PRSs exhibited significantly poorer transferability and substantially lower effect sizes in individuals of African ancestry, and to a lesser extent, in South Asian and East Asian ancestries. This large-scale empirical evidence underscores the immediate challenge of ancestral bias in genomic data and highlights the potential for the clinical implementation of current PRSs to exacerbate existing health disparities."
  },
  {
    "objectID": "pgs/mars_2022_35591975.html#study-design-and-data",
    "href": "pgs/mars_2022_35591975.html#study-design-and-data",
    "title": "Genome-wide risk prediction of common diseases across ancestries in one million people",
    "section": "Study Design and Data",
    "text": "Study Design and Data\nThe study utilized a combined dataset of approximately one million individuals across six major biobanks: BioBank Japan, Estonian Biobank, FinnGen, HUNT, Mass General Brigham (MGB) Biobank, and UK Biobank. The ancestries evaluated included European, South Asian, East Asian, and African.\n\nPRS Calculation and Evaluation\n\nPRS Method: Genome-wide PRSs were calculated using LDpred, a method that accounts for linkage disequilibrium (LD) and uses a Bayesian approach to estimate SNP effect sizes, incorporating over 6 million variants for each disease.\nInput Data: The input weights were obtained from the largest publicly available, non-overlapping Genome-Wide Association Studies (GWASs) for each of the four diseases.\nTransferability Assessment: Transferability was assessed by comparing the Odds Ratios (OR) per standard deviation (SD) increase in PRS across different global ancestry groups, and also within European populations (including a population isolate, Finland)."
  },
  {
    "objectID": "pgs/mars_2022_35591975.html#key-results-on-transferability",
    "href": "pgs/mars_2022_35591975.html#key-results-on-transferability",
    "title": "Genome-wide risk prediction of common diseases across ancestries in one million people",
    "section": "Key Results on Transferability",
    "text": "Key Results on Transferability\n\nGlobal Ancestry Disparities\nA clear gradient of PRS accuracy was observed, directly correlated with the genetic distance from the primary European GWAS training cohorts:\n\nEuropean Ancestry: The PRSs showed consistently high and similar effect sizes (ORs) across various European populations and health-care systems, suggesting good utility for risk stratification.\nAsian Ancestry: Individuals of South Asian and East Asian ancestry exhibited similar or slightly lower effect sizes compared to Europeans.\nAfrican Ancestry: Individuals of African ancestry consistently had the lowest effect sizes and poorest prediction accuracy for all four diseases. For instance, in breast cancer, the association was not statistically significant in women of African ancestry in some cohorts.\n\n\n\nSubstructure and Polygenicity\n\nWithin-European Transferability: The PRSs transferred well even between highly structured European populations, such as various regional substructures within Finland, demonstrating robustness across recent population bottlenecks.\nGenome-wide vs. Sparse PRS: A crucial methodological finding was that the highly polygenic, genome-wide PRSs (using millions of variants) displayed higher effect sizes and better transferability across global ancestries than PRSs containing only a smaller, more stringently selected set of variants (sparse PRSs). This supports the notion that the polygenic nature of these traits is captured across different populations, even if the fine-mapping of causal variants differs."
  },
  {
    "objectID": "pgs/mars_2022_35591975.html#implications-for-clinical-utility",
    "href": "pgs/mars_2022_35591975.html#implications-for-clinical-utility",
    "title": "Genome-wide risk prediction of common diseases across ancestries in one million people",
    "section": "Implications for Clinical Utility",
    "text": "Implications for Clinical Utility\nThe findings provide strong evidence that the current state of PRS technology is not ready for equitable clinical deployment:\n\nClinical Utility: Current PRSs have demonstrated significant potential for clinical screening and prevention in individuals of European ancestry.\nHealth Equity Concern: The low predictive accuracy in individuals of African ancestry, South Asian, and East Asian ancestry—stemming from the lack of diversity in the original GWAS training data—poses a significant challenge to global health equity and personalized medicine. The study stresses the urgent necessity of investing in and executing large-scale GWAS in non-European populations to address this bias."
  },
  {
    "objectID": "index.html#proteomics",
    "href": "index.html#proteomics",
    "title": "",
    "section": "proteomics",
    "text": "proteomics"
  },
  {
    "objectID": "index.html#metabolomics",
    "href": "index.html#metabolomics",
    "title": "",
    "section": "metabolomics",
    "text": "metabolomics"
  },
  {
    "objectID": "index.html#multi-omics",
    "href": "index.html#multi-omics",
    "title": "",
    "section": "multi-omics",
    "text": "multi-omics"
  },
  {
    "objectID": "index.html#statistics",
    "href": "index.html#statistics",
    "title": "",
    "section": "statistics",
    "text": "statistics"
  },
  {
    "objectID": "index.html#mr",
    "href": "index.html#mr",
    "title": "",
    "section": "MR",
    "text": "MR"
  },
  {
    "objectID": "mr.html",
    "href": "mr.html",
    "title": "Proteomics",
    "section": "",
    "text": "test\ntest"
  },
  {
    "objectID": "genetics.html",
    "href": "genetics.html",
    "title": "genetics",
    "section": "",
    "text": "Specificity, length and luck drive gene rankings in association studies\n\nSystematic comparison of GWAS and rare variant burden tests across 209 UK Biobank traits revealing they prioritize different genes through distinct mechanisms\nBurden tests favor trait-specific genes while GWAS capture both trait-specific genes and context-specific variants on pleiotropic genes\nGene length and genetic drift are major confounders affecting rankings in burden tests and GWAS respectively\n\n\n\nmetaGE: Investigating genotype x environment interactions through GWAS meta-analysis\n\nNovel meta-analysis approach for multi-environment trials (METs) that jointly analyzes GWAS summary statistics while accounting for inter-environment correlations\nControls Type I error effectively (FDR ≤0.05) where competing methods fail severely (METAL FDR &gt;0.84), with computational efficiency enabling analysis of 600K markers × 22 environments in ~2 minutes\nIdentified novel competition-responsive flowering QTLs in Arabidopsis and heat-stress yield QTLs in maize through contrast tests and meta-regression with environmental covariates\n\n\n\nUsing GWAS summary data to impute traits for genotyped individuals\n\nNovel nonparametric LS-imputation method recovers genetic components of traits from GWAS summary statistics and individual genotypes, enabling nonlinear association analyses impossible with summary data alone\nPerfectly recovers trait values when test genotypes match training genotypes (correlation &gt;0.999), capturing nonlinear SNP-trait information despite using only linear marginal associations\nOutperforms PRS-CS for association analyses in UK Biobank HDL data: successfully detects non-additive genetic effects, SNP-SNP interactions, and trains nonlinear prediction models (random forests) while PRS-CS shows severe false positive inflation\n\n\n\nAdjusting for Heritable Covariates Can Bias Effect Estimates in Genome-Wide Association Studies\n\nAdjusting a Genome-Wide Association Study (GWAS) for a heritable covariate (a correlated, genetically influenced trait) introduces an unintended collider bias, which distorts SNP effect estimates and can lead to false positive associations.\nThe bias is approximately proportional to the product of the genetic effect on the covariate and the phenotypic correlation between the traits, and was empirically confirmed by finding a significant enrichment of SNPs with opposite effects in the WHR adjusted for BMI GWAS (\\(p=0.005\\)).\nThe authors strongly caution against interpreting adjusted results as true direct genetic effects, recommending unadjusted GWAS for total effect discovery and bivariate methods for power gains without inducing collider bias.\n\n\n\nGenetic architecture: the shape of the genetic contribution to human traits and disease\n\nThis review defines genetic architecture by four components: the number of causal variants (polygenicity), the distribution of their effect sizes, their allele frequency spectrum, and the types of genetic and environmental interactions (dominance, epistasis, GxE).\nIt highlights that complex traits are highly polygenic and influenced by variants across the entire frequency spectrum, addressing “missing heritability” by pointing to the role of rare variants, non-additive effects, and Gene-by-Environment (GxE) interactions.\nThe authors emphasize that pleiotropy (one variant affecting multiple traits) is widespread among common variants, discussing how techniques like Mendelian Randomization (MR) are essential for distinguishing causation from pleiotropy in the complex genetic landscape.\n\n\n\nGenome-wide association scans for secondary traits using case-control samples\n\nThis statistical methodology paper examines the bias introduced when a case-control GWAS (designed for a primary disease \\(D\\)) is used to analyze a secondary quantitative trait (\\(T\\)).\nIt demonstrates that naïve analysis (ignoring case-control ascertainment) leads to biased effect estimates for the marker-secondary trait association (\\(G-T\\)) specifically when both the marker \\(G\\) and the trait \\(T\\) are independently associated with the primary disease \\(D\\).\nThe authors propose using Inverse-Probability-of-Sampling-Weighted (IPW) regression as the robust method, which provides unbiased estimates in all scenarios, though at the cost of reduced statistical power, recommending naïve analysis for markers not associated with the primary disease."
  },
  {
    "objectID": "statistics/hernan_2025_39494894.html",
    "href": "statistics/hernan_2025_39494894.html",
    "title": "A Structural Description of Biases That Generate Immortal Time",
    "section": "",
    "text": "PubMed: 39494894 DOI: 10.1097/EDE.0000000000001808 Overview generated by: Gemini 2.5 Flash, 26/11/2025"
  },
  {
    "objectID": "statistics/hernan_2025_39494894.html#key-concepts-and-goal",
    "href": "statistics/hernan_2025_39494894.html#key-concepts-and-goal",
    "title": "A Structural Description of Biases That Generate Immortal Time",
    "section": "Key Concepts and Goal",
    "text": "Key Concepts and Goal\nImmortal time is defined as an event-free period included in a survival analysis during which a person, by definition, cannot experience the event of interest. The authors argue that the term “immortal time bias” is misleading because the bias is not generated by the time itself, but by the underlying selection or misclassification that creates the immortal time. The primary goal of the paper is to review the two mechanisms that produce immortal time and to propose causal diagrams to represent them.\nThe ultimate prevention strategy is Target Trial Emulation, which explicitly specifies eligibility and assignment to the treatment strategies and synchronizes them at the start of follow-up. This alignment prevents the selection and misclassification that lead to immortal time."
  },
  {
    "objectID": "statistics/hernan_2025_39494894.html#mechanism-1-immortal-time-due-to-selection",
    "href": "statistics/hernan_2025_39494894.html#mechanism-1-immortal-time-due-to-selection",
    "title": "A Structural Description of Biases That Generate Immortal Time",
    "section": "Mechanism 1: Immortal Time Due to Selection",
    "text": "Mechanism 1: Immortal Time Due to Selection\nThis mechanism arises when an eligibility criterion is (incorrectly) applied after the start of follow-up (i.e., after treatment assignment).\n\nStudy Design Failure\nThe issue is created when researchers restrict the analysis to individuals who survived or completed a certain period of follow-up after the initial treatment assignment. For example, if follow-up data for the first 3 months are accidentally deleted, or if an observational analysis is restricted to individuals who have completed 3 months of follow-up, the resulting dataset only contains survivors, creating an “immortal” period where all included individuals survived.\n\n\nResulting Bias\n\nThe selection of surviving individuals results in selection bias due to a differential exclusion of the individuals most susceptible to the outcome in each treatment group.\nIf the follow-up is started at the time of treatment assignment but the immortal period is included, the resulting selection bias is often called “immortal time bias.”\nIf the follow-up is started after the immortal period (e.g., using a landmark approach), the resulting bias is sometimes referred to as “prevalent user bias.”\n\n\n\nSolution\nTo prevent this bias, researchers must ensure that all eligibility criteria are defined at time zero so that no selection occurs after treatment assignment. This is naturally achieved by explicitly emulating a target trial based on data for all eligible individuals from the time of treatment assignment."
  },
  {
    "objectID": "statistics/hernan_2025_39494894.html#mechanism-2-immortal-time-due-to-misclassification",
    "href": "statistics/hernan_2025_39494894.html#mechanism-2-immortal-time-due-to-misclassification",
    "title": "A Structural Description of Biases That Generate Immortal Time",
    "section": "Mechanism 2: Immortal Time Due to Misclassification",
    "text": "Mechanism 2: Immortal Time Due to Misclassification\nThis mechanism occurs when individuals are misclassified into a treatment group that differs from the one they were assigned to, typically because the treatment strategies under study are not distinguishable at time zero.\n\nStudy Design Failure\nThis arises when a treatment strategy includes a grace period or a waiting period (e.g., “start treatment within 3 months” vs. “never start treatment”). If the assignment indicator (\\(Z\\)) is deleted (or unknown in observational data), researchers might reconstruct an assignment (\\(Z^*\\)) based on whether the individual actually received treatment during the grace period. This forces individuals who were assigned to treatment but died before starting it to be classified into the “no treatment” group.\n\n\nResulting Bias\n\nThis reconstruction uses information on the outcome (survival until treatment) to define the assignment variable \\(Z^*\\), which is a violation of the rule that assignment at time zero must not depend on future outcome values.\nThe resulting error is outcome-dependent misclassification, which makes the treated group look artificially “immortal” during the grace period (as anyone who died before treatment is excluded from the \\(Z^*\\) group).\n\n\n\nSolutions\n\nChange the Causal Question: Re-define the comparison to strategies that are distinguishable at time zero (e.g., comparing immediate treatment to no treatment today).\nCloning Followed by Censoring: Create multiple “clones” of each individual for every treatment strategy compatible with their data at baseline. Each clone is censored if they deviate from the assigned strategy. This approach requires inverse-probability weighting to adjust for the induced selection bias.\nPlug-in G-Formula: A complex estimation approach requiring the modeling of the joint distribution or iterated conditional expectation of time-varying treatment, outcome, and confounders."
  },
  {
    "objectID": "statistics/hernan_2025_39494894.html#cautionary-note-on-alternative-methods",
    "href": "statistics/hernan_2025_39494894.html#cautionary-note-on-alternative-methods",
    "title": "A Structural Description of Biases That Generate Immortal Time",
    "section": "Cautionary Note on Alternative Methods",
    "text": "Cautionary Note on Alternative Methods\nWhile landmark analysis and person-time analysis can avoid immortal time, they do not explicitly specify the target trial and do not eliminate the fundamental misalignment of eligibility and assignment. These methods can still be susceptible to bias (like selection bias for landmark analysis) or rely on implausible assumptions (like the constant hazard ratio assumption for person-time analysis)."
  },
  {
    "objectID": "statistics/debertin_2024_38860706.html",
    "href": "statistics/debertin_2024_38860706.html",
    "title": "Synthesizing Subject-matter Expertise for Variable Selection in Causal Effect Estimation: A Case Study",
    "section": "",
    "text": "PubMed: 38860706 DOI: 10.1097/EDE.0000000000001758 Overview generated by: Gemini 2.5 Flash, 26/11/2025"
  },
  {
    "objectID": "statistics/debertin_2024_38860706.html#background-and-purpose",
    "href": "statistics/debertin_2024_38860706.html#background-and-purpose",
    "title": "Synthesizing Subject-matter Expertise for Variable Selection in Causal Effect Estimation: A Case Study",
    "section": "Background and Purpose",
    "text": "Background and Purpose\nDirected Acyclic Graphs (DAGs) are a crucial theoretical tool for covariate selection in causal effect estimation, as they allow researchers to identify minimal adjustment sets that control for confounding. However, there is limited empirical research on the practical creation of these graphs. This paper assesses different approaches to DAG construction using data from the Coronary Drug Project (CDP) trial. The focus is on estimating the effect of placebo adherence on mortality, a relationship where the true causal effect is assumed to be zero (as a placebo cannot cause mortality), providing a robust benchmark for comparing methods."
  },
  {
    "objectID": "statistics/debertin_2024_38860706.html#study-methods-and-design",
    "href": "statistics/debertin_2024_38860706.html#study-methods-and-design",
    "title": "Synthesizing Subject-matter Expertise for Variable Selection in Causal Effect Estimation: A Case Study",
    "section": "Study Methods and Design",
    "text": "Study Methods and Design\nThe authors created multiple DAGs based on various strategies for identifying and linking variables. For each DAG, the corresponding minimal adjustment sets were derived to control for confounding variables. These adjustment sets were then applied to the CDP data under two primary modeling strategies:\n\nBaseline-only Adjustment: Estimating the cumulative effect of adherence on mortality by adjusting only for baseline covariate values in a standard regression.\nTime-Varying Adjustment: Estimating the effect by adjusting for time-varying covariates of adherence using Inverse Probability Weighting (IPW)."
  },
  {
    "objectID": "statistics/debertin_2024_38860706.html#empirical-results",
    "href": "statistics/debertin_2024_38860706.html#empirical-results",
    "title": "Synthesizing Subject-matter Expertise for Variable Selection in Causal Effect Estimation: A Case Study",
    "section": "Empirical Results",
    "text": "Empirical Results\n\nEffect of Nonconfounding Prognostic Factors\nWhen estimating the cumulative effect using only baseline covariates, the results showed that the specific choice of covariates had minimal effect on the (expectedly biased) point estimates. However, including nonconfounding prognostic factors (variables that predict the outcome but not the exposure) led to smaller variance estimates. This finding provides empirical support for the theoretical advice that including prognostic factors increases the efficiency of the causal estimate without introducing bias.\n\n\nEffect of Exposure Predictors\nConversely, when using IPW to adjust for time-varying covariates, adjustment sets that included exposure predictors that were not prognostic factors were shown to result in less bias control.\n\n\nPerformance of DAG Creation Strategies\nOverall, the DAGs that were explicitly created by focusing subject-matter expertise on the identification of potential outcome prognostic factors performed best, particularly in the more complex time-varying covariate scenario using IPW."
  },
  {
    "objectID": "statistics/debertin_2024_38860706.html#conclusions-and-recommendations",
    "href": "statistics/debertin_2024_38860706.html#conclusions-and-recommendations",
    "title": "Synthesizing Subject-matter Expertise for Variable Selection in Causal Effect Estimation: A Case Study",
    "section": "Conclusions and Recommendations",
    "text": "Conclusions and Recommendations\n\nConfirmation of Theory\nThe study empirically confirms key theoretical advice regarding causal variable selection:\n\nInclude Prognostic Factors: Identifying and including covariates that are strong predictors of the outcome (prognostic factors) but not predictors of the exposure is highly recommended to reduce variance and increase statistical power.\nCaution with Exposure Predictors: Covariates that are strong predictors of the exposure but not the outcome may interfere with bias control and should be considered with caution.\n\n\n\nPractical Recommendation\nThe paper recommends that researchers and subject-matter experts begin the hand-creation of DAGs with a systematic effort to identify and include all potential outcome prognostic factors, as this strategy proved most effective in constructing a robust adjustment set for causal effect estimation."
  },
  {
    "objectID": "statistics/smith_2018_dyw314.html",
    "href": "statistics/smith_2018_dyw314.html",
    "title": "Step away from stepwise",
    "section": "",
    "text": "PubMed: Not Indexed (Journal of Big Data) DOI: 10.1186/s40537-018-0143-6 Overview generated by: Gemini 2.5 Flash, 26/11/2025"
  },
  {
    "objectID": "statistics/smith_2018_dyw314.html#key-findings-the-dangers-of-stepwise-regression-in-the-era-of-big-data",
    "href": "statistics/smith_2018_dyw314.html#key-findings-the-dangers-of-stepwise-regression-in-the-era-of-big-data",
    "title": "Step away from stepwise",
    "section": "Key Findings: The Dangers of Stepwise Regression in the Era of Big Data",
    "text": "Key Findings: The Dangers of Stepwise Regression in the Era of Big Data\nThis short report by Gary Smith critiques the continued use of stepwise regression, a popular but flawed variable selection method, especially in the context of Big Data. The central argument is that stepwise procedures are fundamentally unable to distinguish between genuine explanatory variables and nuisance variables (spurious correlations), a problem that is dramatically exacerbated when the pool of potential predictors is large.\n\nThe Fundamental Flaws of Stepwise Regression\nStepwise regression (which includes forward selection, backward elimination, and bidirectional methods) uses an arbitrary threshold of statistical significance (p-value) to automate the inclusion or exclusion of variables in a multiple-regression model. The author identifies three major, interconnected problems with this approach:\n\nSelection of Nuisance Variables: By relying solely on statistical significance, stepwise procedures frequently select nuisance variables that happen to be coincidentally significant in the in-sample data. Since these variables have no true causal effect, they are useless for prediction with fresh data (out-of-sample).\nExclusion of True Explanatory Variables: Conversely, genuine explanatory variables with causal effects may be incorrectly excluded because they happen not to be statistically significant in the particular sample analyzed.\nSevere Out-of-Sample Failure: The resulting model, while often providing an excellent fit to the estimation data (high \\(R^2\\) due to including significant noise variables), does poorly out-of-sample. The selection of irrelevant variables provides a false confidence in the estimated model because of the high t-values and the boost to the in-sample \\(R^2\\). ### Big Data Exacerbates the Problem\n\nThe article specifically addresses the belief held by some “Big-Data researchers” that the larger the number of possible explanatory variables, the more useful stepwise regression becomes.\n\nIncreased Chance of Spurious Correlation: In reality, the efficacy of stepwise regression is less effective the larger the number of potential explanatory variables. The sheer number of variables in Big Data increases the probability of finding highly significant but spurious correlations purely by chance.\nWorsening Out-of-Sample Fit: As the number of candidate variables increases, the in-sample fit improves, but the out-of-sample fit deteriorates, causing the ratio of the out-of-sample errors to the in-sample errors to “balloon”.\n\n\n\nConclusion\nThe paper concludes that stepwise regression does not offer a solution to the challenge of too many explanatory variables in the Big Data era; rather, Big Data exacerbates the failings of stepwise regression. The focus should instead be on methods that prioritize predictive accuracy and robust out-of-sample validation."
  },
  {
    "objectID": "statistics/senn_1994_7997705.html",
    "href": "statistics/senn_1994_7997705.html",
    "title": "TESTING FOR BASELINE BALANCE IN CLINICAL TRIALS",
    "section": "",
    "text": "PubMed: 7997705 DOI: 10.1002/sim.4780131610 Overview generated by: Gemini 2.5 Flash, 26/11/2025"
  },
  {
    "objectID": "statistics/senn_1994_7997705.html#key-findings-the-misguided-practice-of-testing-baseline-balance",
    "href": "statistics/senn_1994_7997705.html#key-findings-the-misguided-practice-of-testing-baseline-balance",
    "title": "TESTING FOR BASELINE BALANCE IN CLINICAL TRIALS",
    "section": "Key Findings: The Misguided Practice of Testing Baseline Balance",
    "text": "Key Findings: The Misguided Practice of Testing Baseline Balance\nThis influential paper by Stephen Senn critiques the common, but statistically unsound, practice in randomized controlled trials (RCTs) of performing “tests of baseline homogeneity” (i.e., p-value tests comparing baseline characteristics between treatment arms) before proceeding to analyze the treatment effect on the outcome. Senn argues that this practice is both philosophically flawed and practically misleading.\n\nThe Problem with Testing for Balance\nThe core issue lies in the interpretation of randomization and the nature of the null hypothesis in a properly conducted RCT:\n\nPhilosophically Unsound: The goal of randomization is to ensure that, in expectation, the treatment groups are comparable. Any observed differences at baseline are due purely to chance, and no statistical test is required to confirm this. Performing a test is equivalent to testing the effectiveness of a coin toss—a pointless exercise.\nNo Practical Value: A statistically significant difference at baseline (e.g., \\(p &lt; 0.05\\) for age difference) does not indicate a flaw in the randomization process; it is merely a low-probability chance event that is expected to occur in 5% of all covariates tested. Such a finding offers no useful guidance on how to analyze the treatment effect.\nPotentially Misleading:\n\nNon-significant difference (\\(p &gt; 0.05\\)): This does not prove the groups are “balanced” or comparable. It only means the study lacked the power to detect a difference, or that the observed difference was not large enough to cross the arbitrary significance threshold. The non-significant result might wrongly convince the investigator that no adjustment is needed, even if the difference is clinically important.\nSignificant difference (\\(p &lt; 0.05\\)): This may wrongly prompt an investigator to use an ad hoc adjustment (like Analysis of Covariance, ANCOVA) only for that specific variable, introducing subjectivity into the analysis plan and potentially invalidating the comparison of treatment effects.\n\n\n\n\nThe Recommended Practice: Analysis of Covariance (ANCOVA)\nSenn strongly recommends replacing baseline balance testing with a principled approach to analysis:\n\nPre-specify Prognostic Variables: The study protocol should identify and list all known or suspected prognostic covariates (variables predictive of the outcome), regardless of their baseline distribution.\nRoutine ANCOVA: These prognostic variables should be included in the primary analysis model using Analysis of Covariance (ANCOVA), irrespective of their p-value from the baseline comparison.\nStatistical Advantages: Adjusting for important prognostic variables using ANCOVA increases the precision and statistical power of the treatment effect estimate, leading to narrower confidence intervals. Crucially, the validity of ANCOVA in an RCT relies on the fact that randomization ensures the baseline covariates are unrelated to the treatment assignment, not on their baseline p-value.\n\n\n\nConclusion\nThe paper concludes that the practice of baseline testing is a confusion of philosophy and statistics. Researchers should focus on design (randomization) to ensure validity and statistical efficiency (ANCOVA) to maximize power, rather than using post-randomization tests that are incapable of fulfilling the purpose for which they are intended."
  },
  {
    "objectID": "statistics/dewalsche_2025_40918066.html",
    "href": "statistics/dewalsche_2025_40918066.html",
    "title": "Large-scale composite hypothesis testing procedure for omics data analyses",
    "section": "",
    "text": "PubMed: 40918066\nDOI: 10.1093/nargab/lqaf118\nOverview generated by: Claude Sonnet 4.5, 25/11/2025"
  },
  {
    "objectID": "statistics/dewalsche_2025_40918066.html#key-findings",
    "href": "statistics/dewalsche_2025_40918066.html#key-findings",
    "title": "Large-scale composite hypothesis testing procedure for omics data analyses",
    "section": "Key Findings",
    "text": "Key Findings\nThis study introduces qch_copula, a novel composite hypothesis testing (CHT) method for analyzing multiple traits or omics levels simultaneously, addressing key limitations in existing approaches for large-scale genomic studies.\n\nMain Discoveries\n\nNovel P-value derivation: First method to provide rigorously defined P-values directly from mixture model approaches for composite hypothesis testing\nSuperior performance: qch_copula effectively controls Type I error rates while maintaining higher detection power compared to eight state-of-the-art methods (DACT, HDMT, PLACO, adaFilter, IMIX, c-csmGmm, Primo, qch)\nScalability breakthrough: Memory-efficient EM algorithm reduces storage from O(n × 2^Q) to O(n + 2^Q), enabling analysis of up to 20 traits and 105-106 markers\nDependency modeling: Explicitly accounts for correlations between traits/omics levels through copula functions, improving false positive control"
  },
  {
    "objectID": "statistics/dewalsche_2025_40918066.html#study-design",
    "href": "statistics/dewalsche_2025_40918066.html#study-design",
    "title": "Large-scale composite hypothesis testing procedure for omics data analyses",
    "section": "Study Design",
    "text": "Study Design\n\nMethodological Framework\nThe method addresses testing composite null hypotheses of the form H₀: “a marker/gene has effects in at most q̃ - 1 conditions” versus H₁: “effects in at least q̃ conditions.”\nKey components: - Mixture model with 2^Q components (one per configuration) - Gaussian copula to capture dependencies between conditions - Nonparametric estimation of alternative distributions - Two-step inference: marginal distributions, then proportions and copula parameters\n\n\nModel Specification\nFor Q conditions, z-scores (negative probit transforms of P-values) follow:\n\\[Z_i \\sim \\sum_{c \\in C} w_c \\psi_c\\]\nwhere each component ψ_c combines: - Univariate marginal distributions F^q_0 (null) and F^q_1 (alternative) - Copula function C_θ describing dependencies\nPosterior-based P-value:\n\\[\\text{pval}(z) = \\frac{1}{n\\hat{W}_0} \\sum_{j=1}^n \\mathbb{1}_{\\{\\hat{\\tau}_j &gt; \\hat{\\tau}_i\\}} (1 - \\hat{\\tau}_j)\\]\nwhere τ represents the posterior probability of belonging to alternative configurations."
  },
  {
    "objectID": "statistics/dewalsche_2025_40918066.html#major-results",
    "href": "statistics/dewalsche_2025_40918066.html#major-results",
    "title": "Large-scale composite hypothesis testing procedure for omics data analyses",
    "section": "Major Results",
    "text": "Major Results\n\nSimulation Study Design\nEvaluated across 24 settings varying: - Number of conditions: Q = 2, 8, 16 - Correlation levels: ρ = 0, 0.3, 0.5, 0.7 - Scenarios: sparse (≥90% null) vs. dense (50% alternative) - Sample size: n = 10^5 markers\n\n\nType I Error Control (Q = 2)\nIndependent traits (ρ = 0): - Most methods controlled FDR at nominal 5% level - DACT-JC showed substantial inflation (~0.25) - Minor deviations for PLACO and c-csmGmm (~0.08)\nCorrelated traits (ρ = 0.3): - Only DACT_Efron and qch_copula maintained proper FDR control - qch showed severe inflation (FDR = 0.256 sparse, 0.145 dense) - HDMT, PLACO, IMIX, c-csmGmm all exceeded nominal level\nHigher correlations (ρ = 0.5, 0.7): - qch_copula consistently controlled FDR near 0.05 - Other methods (except DACT_Efron) showed increased inflation\n\n\nType I Error Control (Q = 8, 16)\nQ = 8 with ρ = 0.3: - All three scalable methods (Primo, adaFilter, qch_copula) controlled FDR - Primo and adaFilter were conservative (FDR &lt; 0.02 in most cases) - qch_copula maintained FDR close to nominal level\nQ = 16 with ρ = 0.3: - qch_copula: slight inflation in sparse scenario (FDR ≤ 0.08) - adaFilter: comparable performance - Primo: computational failure (&gt;24h runtime or memory exhaustion)\nSpatial dependence (ξ = 0.3): - Improved FDR control for qch_copula and Primo - No impact on adaFilter - qch_copula reduced FDR from ~0.11 to &lt;0.065 in challenging scenarios\n\n\nDetection Power\nQ = 2: - DACT_Efron: zero power (too conservative) - qch_copula: 0.03-0.124 depending on scenario\nQ = 8, ρ = 0.3:\n\n\n\nTesting hypothesis\nPrimo Power\nadaFilter Power\nqch_copula Power\n\n\n\n\n≥2 traits (dense)\n0.143\n0.317\n0.609\n\n\n≥4 traits (dense)\n0.126\n0.148\n0.534\n\n\n≥8 traits (dense)\n0.125\n0.033\n0.186\n\n\n\nQ = 16, ρ = 0.3:\n\n\n\nTesting hypothesis\nadaFilter Power\nqch_copula Power\n\n\n\n\n≥2 traits (dense)\n0.278\n0.646\n\n\n≥4 traits (dense)\n0.166\n0.678\n\n\n≥8 traits (sparse)\n0.097\n0.568\n\n\n\nqch_copula showed 6× higher power than adaFilter for detecting associations with ≥8 traits in sparse scenarios."
  },
  {
    "objectID": "statistics/dewalsche_2025_40918066.html#computational-efficiency",
    "href": "statistics/dewalsche_2025_40918066.html#computational-efficiency",
    "title": "Large-scale composite hypothesis testing procedure for omics data analyses",
    "section": "Computational Efficiency",
    "text": "Computational Efficiency\n\nMemory-Efficient EM Algorithm\nClassical approach: Stores full posterior matrix T = (τ_ic) requiring 26 GB for n=10^5, Q=15\nqch_copula approach: - Computes posteriors on-the-fly during M-step - Stores only summary statistics S^(t)_i - Reduces memory from 26 GB to 1 MB (same example)\nRuntime (Q=16, n=10^5): - Model fitting: 78 minutes - Per hypothesis test: ~1 minute - Platform: Single thread, 3.2 GB RAM"
  },
  {
    "objectID": "statistics/dewalsche_2025_40918066.html#application-i-psychiatric-disorders",
    "href": "statistics/dewalsche_2025_40918066.html#application-i-psychiatric-disorders",
    "title": "Large-scale composite hypothesis testing procedure for omics data analyses",
    "section": "Application I: Psychiatric Disorders",
    "text": "Application I: Psychiatric Disorders\n\nDataset\n\n14 psychiatric disorders from Psychiatric Genomics Consortium\n5,172,884 common SNPs\nObjective: Identify pleiotropic regions associated with ≥8 disorders\n\n\n\nComparison with PLACO\nOriginal analysis (PLACO): - Aggregated SNPs to 26,024 genes using MAGMA - Performed 91 pairwise analyses (all combinations of 2 disorders) - Identified 38 candidate genes\nqch_copula analysis: - Direct SNP-level analysis (no aggregation) - Single joint test across all 14 disorders - Identified 1,608 SNPs in 28 distinct regions\n\n\nNovel Findings\n35/38 PLACO genes confirmed plus 8 new regions:\n\n\n\nRegion\nChr\nPosition (Mb)\n# SNPs\nTop SNP P-value\n\n\n\n\nNovel 1\n5\n103.6-104.0\n338\n5.16×10^-12\n\n\nNovel 2\n1\n73.8-73.9\n156\n1.01×10^-7\n\n\nNovel 3\n3\n52.6-53.1\n90\n7.27×10^-8\n\n\n\nChromosome 5 region (top finding): - 338 SNPs detected - 25 SNPs associated with 11 disorders - Overlaps with RP11-6N13.1 gene - Previously reported for ADHD, ASD, BIP, MDD, SCZ, TS\nThree PLACO-only genes (NEGR1, TMX2, C11orf31): - Had only 3-7 P-values &lt;0.01 out of 14 (insufficient for ≥8 disorders) - Likely false positives from pairwise approach"
  },
  {
    "objectID": "statistics/dewalsche_2025_40918066.html#application-ii-cucumber-virus-resistance",
    "href": "statistics/dewalsche_2025_40918066.html#application-ii-cucumber-virus-resistance",
    "title": "Large-scale composite hypothesis testing procedure for omics data analyses",
    "section": "Application II: Cucumber Virus Resistance",
    "text": "Application II: Cucumber Virus Resistance\n\nDataset\n\n289 cucumber lines (elite, landraces, hybrids)\n6 viruses: CGMMV, CMV, CVYV, PRSV, WMV, ZYMV\n339,804 common SNPs (after QC)\nObjective: Detect QTLs for multi-virus resistance\n\n\n\nResults by Pleiotropy Level\n\n\n\nNumber of viruses\n# SNPs detected\n# Regions\n\n\n\n\n≥2\n1,845\n5\n\n\n≥3\n164\n1\n\n\n≥4\n15\n1\n\n\n\n\n\nIdentified Hotspot Regions\nFive regions associated with ≥2 viruses:\n\n\n\nRegion\nViruses\nOriginal study\nExternal validation\n\n\n\n\nChr 5: 6.3-8.8 Mb\nWMV, CGMMV, CVYV, CMV\nReported\n-\n\n\nChr 6: 6.8-14.7 Mb\nPRSV, ZYMV\nReported\n-\n\n\nChr 1: 9.1-10.1 Mb\n-\nNovel\n-\n\n\nChr 2: 1.3 Mb\nPRSV, ZYMV\nNovel\nCMV, CABYV QTLs\n\n\nChr 6: 22.8-26.4 Mb\nPRSV, ZYMV\nNovel\nWMV, CABYV QTLs\n\n\n\nThree novel regions not reported in original study: - Two validated by independent studies showing shared resistance mechanisms - Demonstrates enhanced power of joint analysis over individual GWAS"
  },
  {
    "objectID": "statistics/dewalsche_2025_40918066.html#methodological-insights",
    "href": "statistics/dewalsche_2025_40918066.html#methodological-insights",
    "title": "Large-scale composite hypothesis testing procedure for omics data analyses",
    "section": "Methodological Insights",
    "text": "Methodological Insights\n\nAdvantages over Existing Methods\nMixture model approaches (IMIX, c-csmGmm, Primo): - Fully parametric: constrain alternative distributions to Gaussian - qch_copula: nonparametric estimation with copula dependencies\nPairwise methods (PLACO, HDMT): - Limited to Q=2 - Multiple pairwise tests lack statistical guarantees for joint inference - Can produce inconsistent results\nFiltering methods (adaFilter): - More conservative - Lower power for stringent hypotheses\n\n\nP-values vs. Posteriors\nqch_copula establishes theoretical equivalence between: - Adaptive Benjamini-Hochberg FDR control on derived P-values - Local FDR control on posteriors\nAdvantages of P-values: - Compatible with any multiple testing procedure - Enable diagnostic tools (QQ-plots, histograms) - Allow Volcano/Manhattan plots - Facilitate method comparison\n\n\nCopula Modeling Strategy\nSingle correlation matrix across all components: - Balances model flexibility and computational efficiency - Avoids poor estimation from under-represented components - Captures essential dependency structure\nAlternative approaches: - Component-specific matrices (IMIX): computationally prohibitive - No dependencies (qch): severe Type I error inflation\n\n\nRobustness to Dependencies\nWithin-series correlation (ξ = 0.3): - Minimal impact on most methods - Actually improved FDR control for qch_copula - Particularly beneficial in challenging scenarios (Q=16)\nFurther options: - Combine with dependency-aware multiple testing procedures - Apply local score techniques for spatial clustering"
  },
  {
    "objectID": "statistics/dewalsche_2025_40918066.html#practical-recommendations",
    "href": "statistics/dewalsche_2025_40918066.html#practical-recommendations",
    "title": "Large-scale composite hypothesis testing procedure for omics data analyses",
    "section": "Practical Recommendations",
    "text": "Practical Recommendations\n\nChoosing q̃ (Minimum Effect Threshold)\nMultiple strategies: 1. Hypothesis-driven: Based on research question (e.g., pleiotropy → q̃=2) 2. Prior evidence: From previous analyses (e.g., q̃=8 from literature) 3. Cost-benefit: Economic considerations (breeding value of multi-trait resistance) 4. Exploratory: Test multiple q̃ values for ranking\n\n\nMethod Selection\nUse qch_copula when: - Q &gt; 2 traits/conditions - Correlations between traits exist - Need rigorously defined P-values - Large-scale data (105-106 markers, Q ≤ 20) - Testing various composite hypotheses\nConsider alternatives when: - Q = 2 and no dependencies: simpler methods may suffice - Extremely high correlations (ρ &gt; 0.7): expect minor FDR inflation - Need for component-specific direction effects: extensions required\n\n\nImplementation Details\nAvailable in R package qch on CRAN\nKey functions: - Model fitting with copula dependencies - P-value computation for any composite hypothesis - Multiple hypothesis testing without re-estimation"
  },
  {
    "objectID": "statistics/dewalsche_2025_40918066.html#limitations-and-extensions",
    "href": "statistics/dewalsche_2025_40918066.html#limitations-and-extensions",
    "title": "Large-scale composite hypothesis testing procedure for omics data analyses",
    "section": "Limitations and Extensions",
    "text": "Limitations and Extensions\n\nCurrent Limitations\n\nCorrelation levels: Slight FDR inflation at ρ ≥ 0.5 for large Q (16+)\nIndependence assumption: Items assumed independent within series\nDirection agnostic: Does not account for effect signs\nPost-hoc inference: Testing multiple q̃ values raises multiple comparisons issues\n\n\n\nOngoing/Future Work\nEffect direction: - Extension accounting for effect signs available in qch package (independent case) - Copula + direction effects: under development\nWithin-series dependencies: - Compatible with dependency-aware multiple testing - Integration with local score techniques\nModel selection: - Post-hoc inference procedures for q̃ selection"
  },
  {
    "objectID": "statistics/dewalsche_2025_40918066.html#related-concepts",
    "href": "statistics/dewalsche_2025_40918066.html#related-concepts",
    "title": "Large-scale composite hypothesis testing procedure for omics data analyses",
    "section": "Related Concepts",
    "text": "Related Concepts\n\nComposite hypothesis: Union of multiple elementary hypotheses (e.g., H₀¹ ∪ H₀²)\nConfiguration: Vector c = (c₁, …, c_Q) indicating null/alternative status across conditions\nCopula function: Describes dependency structure between marginal distributions\nFlattening: Memory-efficient EM update using on-the-fly computation\nLocal FDR: Posterior probability of belonging to null configuration\nPleiotropy: Single locus affecting multiple traits/phenotypes"
  },
  {
    "objectID": "statistics/mcgowan_2024_2276446.html",
    "href": "statistics/mcgowan_2024_2276446.html",
    "title": "Causal Inference Is Not Just a Statistics Problem",
    "section": "",
    "text": "PubMed: Not Indexed (Journal of Statistics and Data Science Education) DOI: 10.1080/26939169.2023.2276446 Overview generated by: Gemini 2.5 Flash, 26/11/2025"
  },
  {
    "objectID": "statistics/mcgowan_2024_2276446.html#key-findings",
    "href": "statistics/mcgowan_2024_2276446.html#key-findings",
    "title": "Causal Inference Is Not Just a Statistics Problem",
    "section": "Key Findings",
    "text": "Key Findings\nThis article argues that causal inference—the process of determining whether an exposure causes an outcome—is a challenge rooted primarily in study design and conceptual modeling, not just statistical analysis. While statistical methods are necessary for quantifying effects, they cannot salvage a poorly designed study or validate a flawed causal hypothesis.\n\nCausal Inference is Not Statistical Regression\nThe authors emphasize the crucial distinction between prediction/association (a purely statistical exercise) and causal inference (a scientific exercise):\n\nCausality Requires Assumptions: Unlike association, causality requires making strong, often untestable assumptions about the data-generating process. These assumptions include positivity (everyone had a chance to receive the treatment), consistency (the treatment is well-defined), and exchangeability (the treated and untreated groups are comparable, usually requiring control for all confounders).\nStatistics Quantifies, Design Ensures Validity: Statistical methods (like regression, matching, or propensity scores) can only adjust for observed confounding variables under the assumption that all necessary confounders have been identified and measured without error. If a critical confounder is unmeasured (unmeasured confounding), the resulting causal estimate is likely biased, regardless of the sophistication of the statistics used.\n\n\n\nThe Primacy of Study Design\nThe article strongly aligns with the philosophy that “Design Trumps Analysis” (a concept attributed to Donald Rubin).\n\nNeed for Domain Knowledge: The process of identifying the correct causal model and the necessary variables to control (confounders) is a non-statistical process that relies entirely on domain-specific scientific knowledge (e.g., biology, epidemiology, medicine).\nThe “Which Variables to Control?” Problem: The decision of which covariates to include in a regression model is a causal question, not a statistical one. Including a variable that is actually a collider or a mediator can introduce bias where none existed, an error statisticians cannot prevent without external scientific guidance.\nRandomized Controlled Trials (RCTs): RCTs are the gold standard for causal inference precisely because they use a design (randomization) to satisfy the assumption of exchangeability (balance all confounders, measured and unmeasured), thereby circumventing the statistical problem of controlling for confounders.\n\n\n\nConclusion and Education Focus\nThe conclusion stresses that teaching causal inference must go beyond simply running statistical models. Students must be trained to: * Formulate a Causal Question first. * Diagram the Causal Structure using tools like Directed Acyclic Graphs (DAGs). * Identify the Sources of Bias (confounding, selection bias, measurement error) based on their domain knowledge. * Choose a Design (experimental or observational) that minimizes these biases. * Use Statistics only to quantify the effect size within the context of the chosen design and stated causal assumptions."
  },
  {
    "objectID": "statistics/greenland_2016_27209009.html",
    "href": "statistics/greenland_2016_27209009.html",
    "title": "Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations",
    "section": "",
    "text": "PubMed: 27209009 DOI: 10.1007/s10654-016-0149-3 Overview generated by: Gemini 2.5 Flash, 26/11/2025"
  },
  {
    "objectID": "statistics/greenland_2016_27209009.html#key-findings-correcting-the-misinterpretations-of-statistical-inference",
    "href": "statistics/greenland_2016_27209009.html#key-findings-correcting-the-misinterpretations-of-statistical-inference",
    "title": "Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations",
    "section": "Key Findings: Correcting the Misinterpretations of Statistical Inference",
    "text": "Key Findings: Correcting the Misinterpretations of Statistical Inference\nThis essential essay, authored by a collective of prominent statisticians and epidemiologists, provides a detailed guide to the widespread misinterpretations and abuse of basic statistical concepts: P-values, confidence intervals (CIs), and statistical power. It serves as a strong complement to the American Statistical Association’s (ASA) 2016 statement on p-values, emphasizing that these misuses are rampant and lead to profoundly flawed scientific conclusions.\n\nMisinterpretations of the P-value\nThe authors outline 12 common misconceptions about the P-value, which is defined correctly as the probability of observing a test statistic as extreme as, or more extreme than, the one calculated from the data, assuming the null hypothesis (\\(H_0\\)) is true.\nThe paper explicitly states that the P-value is NOT: * The probability that the study hypothesis is true. * The probability that the null hypothesis is true. * The probability that a result is due to chance. * A measure of the magnitude or importance of an effect.\nThey emphasize that a common and disastrous error is using the P-value threshold (e.g., P&lt;0.05) to draw a dichotomous conclusion (i.e., ‘significant’ or ‘non-significant’), which falsely suggests the conclusion is certain or that two studies with slightly different P-values (e.g., P=0.04 and P=0.06) have fundamentally different results.\n\n\nMisinterpretations of Confidence Intervals (CIs)\nThe paper clarifies that a Confidence Interval (CI), commonly 95% CI, is defined by its long-run performance. If one were to repeat the study an infinite number of times, 95% of the CIs constructed would contain the true value of the parameter.\nThe paper stresses that a CI is NOT a probability statement about the parameter in the specific study at hand. Misinterpretations include: * Assuming there is a 95% probability that the true effect lies within the observed interval. * Assuming that values outside the interval are refuted or implausible.\nThe main value of CIs is their ability to convey the precision of the estimate and the range of effect magnitudes that are compatible with the data, encouraging researchers to focus on effect size rather than just statistical significance.\n\n\nMisinterpretations of Statistical Power\nStatistical power is the probability of obtaining a statistically significant result, given a specific assumed effect size and the study’s design.\nThe authors note the main misuses: * Treating power as a continuous measure of study quality; it is highly dependent on the hypothesized effect size. * Misinterpreting low power: A non-significant result from a low-power study does not imply that the true effect is small or non-existent, only that the study was incapable of detecting the hypothesized effect.\n\n\nConclusion\nThe essay’s ultimate conclusion is that statistical inference tools, including P-values, are just one component of scientific reasoning. Their correct use requires attention to design, measurement quality, data integrity, and background knowledge. They recommend using CIs to emphasize effect magnitude and avoiding the common practice of dichotomizing results based on arbitrary P-value thresholds."
  },
  {
    "objectID": "statistics/gururaghavendran_2025_39218433.html",
    "href": "statistics/gururaghavendran_2025_39218433.html",
    "title": "Can algorithms replace expert knowledge for causal inference? A case study on novice use of causal discovery",
    "section": "",
    "text": "PubMed: 39218433 DOI: 10.1093/aje/kwae338 Overview generated by: Gemini 2.5 Flash, 26/11/2025"
  },
  {
    "objectID": "statistics/gururaghavendran_2025_39218433.html#background-and-purpose",
    "href": "statistics/gururaghavendran_2025_39218433.html#background-and-purpose",
    "title": "Can algorithms replace expert knowledge for causal inference? A case study on novice use of causal discovery",
    "section": "Background and Purpose",
    "text": "Background and Purpose\nThis paper addresses the increasing discussion within epidemiology regarding the use of causal discovery algorithms (a form of machine learning) to automate the construction of Causal Directed Acyclic Graphs (DAGs) for covariate selection. The study’s objective was to assess the performance of these data-driven methods, when applied by a novice user, against a known confounded effect: the relationship between placebo adherence and mortality in the Coronary Drug Project (CDP) trial. This relationship is widely accepted to have a true causal effect of null, providing a strong benchmark for evaluating the ability of the algorithms to correctly control for confounding."
  },
  {
    "objectID": "statistics/gururaghavendran_2025_39218433.html#study-design-and-methods",
    "href": "statistics/gururaghavendran_2025_39218433.html#study-design-and-methods",
    "title": "Can algorithms replace expert knowledge for causal inference? A case study on novice use of causal discovery",
    "section": "Study Design and Methods",
    "text": "Study Design and Methods\n\nCausal Discovery Implementation\nThe authors tested 4 common causal discovery algorithms: Peter-Clark (PC), Fast Causal Inference (FCI), Fast Greedy Causal Search (FGES), and Greedy Relaxed Sparsest Permutation (GRaSP). These algorithms were run on the CDP placebo arm data using 39 baseline covariates and the adherence/mortality outcome.\n\n\nParameter Variation\nTo simulate novice use and assess robustness, the authors varied several inputs: 1. Statistical Thresholds: For test-based algorithms (PC, FCI, GRaSP), the \\(\\chi^2\\) alpha level (\\(\\alpha\\)) was varied from 0.001 to 0.20. 2. Prior Knowledge: Models were run with no prior knowledge, a 3-tier time-ordering (covariates \\(\\rightarrow\\) adherence \\(\\rightarrow\\) death), and a 4-tier time-ordering (age/race \\(\\rightarrow\\) other covariates \\(\\rightarrow\\) adherence \\(\\rightarrow\\) death).\n\n\nAdjustment Set Selection\nFrom 17 model parameterizations (including 100 bootstrap samples per ensemble), 15 adjustment sets were identified. Because the bootstrapped results often produced cyclic graphs that could not be resolved into minimally sufficient adjustment sets, the authors adopted a simplification strategy: selecting all covariates identified as potential causes of either mortality or adherence in at least one bootstrap sample."
  },
  {
    "objectID": "statistics/gururaghavendran_2025_39218433.html#key-findings-residual-bias-and-subjectivity",
    "href": "statistics/gururaghavendran_2025_39218433.html#key-findings-residual-bias-and-subjectivity",
    "title": "Can algorithms replace expert knowledge for causal inference? A case study on novice use of causal discovery",
    "section": "Key Findings: Residual Bias and Subjectivity",
    "text": "Key Findings: Residual Bias and Subjectivity\n\nPerformance\n\nBaseline-only Adjustment: The adjustment sets identified by the algorithms, when used to adjust for only baseline covariates, performed similarly to prior published results by achieving a roughly 36% reduction of bias from the unadjusted relationship.\nTime-Varying Adjustment (IPW): When more complex methods were used (Inverse Probability Weighting) to adjust for time-varying confounding, the adjustment sets from the causal discovery algorithms resulted in more residual bias compared to the adjustment sets selected by the original CDP expert team.\n\n\n\nChallenges and Subjectivity\n\nInconsistent Results: Varying the input parameters and algorithm type resulted in a wide range of unique adjustment sets. Only about half of the resulting analyses showed compatibility with the known null effect.\nExpert Knowledge Value: The use of time-ordering (prior knowledge) was essential for improving the interpretability of the resulting graphs, particularly concerning temporal relationships like age and race.\nMethodological Difficulty: The use of bootstrap samples frequently led to cyclic graphs, requiring subjective decisions on simplification and adjustment set selection, which introduces substantial subjectivity into the process."
  },
  {
    "objectID": "statistics/gururaghavendran_2025_39218433.html#conclusions-and-recommendations",
    "href": "statistics/gururaghavendran_2025_39218433.html#conclusions-and-recommendations",
    "title": "Can algorithms replace expert knowledge for causal inference? A case study on novice use of causal discovery",
    "section": "Conclusions and Recommendations",
    "text": "Conclusions and Recommendations\nThe study concludes that while causal discovery algorithms can partially replicate expert findings, their use is not straightforward and introduces a significant degree of subjectivity through the selection of algorithms, input parameters, and interpretation of non-acyclic graphs.\nThe authors strongly recommend that researchers without detailed knowledge of causal discovery algorithms not attempt to use these tools without the aid of an expert in the field. Absent this expert support, the use of traditional subject matter experts to generate causal graphs provides greater transparency about the assumptions made and, in this case study, yielded the best estimate of the true causal effect."
  },
  {
    "objectID": "statistics/hoenig_2001.html",
    "href": "statistics/hoenig_2001.html",
    "title": "The Abuse of Power: The Pervasive Fallacy of Power Calculations for Data Analysis",
    "section": "",
    "text": "PubMed: Not Indexed (The American Statistician) DOI: 10.1080/00031305.2001.10473582 Overview generated by: Gemini 2.5 Flash, 26/11/2025"
  },
  {
    "objectID": "statistics/hoenig_2001.html#key-finding-the-fallacy-of-retrospective-power-analysis",
    "href": "statistics/hoenig_2001.html#key-finding-the-fallacy-of-retrospective-power-analysis",
    "title": "The Abuse of Power: The Pervasive Fallacy of Power Calculations for Data Analysis",
    "section": "Key Finding: The Fallacy of Retrospective Power Analysis",
    "text": "Key Finding: The Fallacy of Retrospective Power Analysis\nThis article by Hoenig and Heisey critically examines and rejects the common practice of performing post-experiment or retrospective power calculations (also called “observed power”) to interpret a statistically non-significant result (i.e., a failure to reject the null hypothesis, \\(H_0\\)).\n\nThe Flawed Logic of Retrospective Power\nThe authors demonstrate that the use of retrospective power as an aid to interpretation is fundamentally flawed because it is a simple monotonic transformation of the p-value.\n\nDefinition: Retrospective power (or observed power) is typically calculated as the statistical power to detect the observed effect size using the observed sample size and the observed variance.\nThe Circularity Problem: Because the observed effect size is used as the hypothetical “true” effect, the retrospective power calculation is nearly equivalent to the p-value:\n\nA small p-value (significant result) will always lead to a high retrospective power.\nA large p-value (non-significant result) will always lead to a low retrospective power.\n\nNo New Information: Retrospective power provides no additional information beyond what is already contained in the p-value and the confidence interval. Stating that a non-significant result had low power is merely restating the finding that the confidence interval around the point estimate is wide enough to include the null hypothesis.\n\n\n\nWhy the Flaw is Pervasive\nThe practice of retrospective power analysis stems from a misunderstanding of the dilemma of the nonrejected null hypothesis: when we fail to reject \\(H_0\\), we want to know if it’s because the true effect is small (or zero), or because the study lacked power to detect an important effect.\n\nMisleading Interpretation: Advocates of retrospective power claim that a low observed power, combined with a non-significant test, suggests the result is “inconclusive” and that a “Type II error” (failing to reject a false \\(H_0\\)) is likely.\nThe Correct Interpretation: A non-significant result means that the data are consistent with the null hypothesis (\\(H_0\\) being true). The only way to address the dilemma is by looking at the confidence interval to see if it excludes effect sizes that are considered biologically or clinically important.\n\n\n\nRecommendation\nThe authors recommend that statistical power should be used only for planning an experiment (prospective analysis). To interpret the results of a completed study, especially a non-significant finding, researchers should focus on:\n\nThe p-value.\nThe point estimate (observed effect size).\nThe confidence interval (which indicates the range of true effects consistent with the data).\n\nThe confidence interval is the superior tool for interpreting non-significant results because it shows whether important effect sizes have been reasonably ruled out, which is the actual goal of most post-hoc power discussions."
  },
  {
    "objectID": "statistics/lawlor_2017_28108528.html",
    "href": "statistics/lawlor_2017_28108528.html",
    "title": "Triangulation in aetiological epidemiology: Approaches to causal inference",
    "section": "",
    "text": "PubMed: 28108528 DOI: 10.1093/ije/dyw314 Overview generated by: Gemini 2.5 Flash, 26/11/2025"
  },
  {
    "objectID": "statistics/lawlor_2017_28108528.html#key-findings-enhancing-causal-inference-through-triangulation",
    "href": "statistics/lawlor_2017_28108528.html#key-findings-enhancing-causal-inference-through-triangulation",
    "title": "Triangulation in aetiological epidemiology: Approaches to causal inference",
    "section": "Key Findings: Enhancing Causal Inference Through Triangulation",
    "text": "Key Findings: Enhancing Causal Inference Through Triangulation\nThis foundational article in aetiological epidemiology advocates for the systematic use of Triangulation—the practice of integrating results from multiple distinct research approaches—to strengthen causal inference in the study of disease aetiology. The authors argue that relying on single methods or studies is inherently problematic due to the limitations and biases specific to that approach.\n\nThe Principle of Triangulation\nTriangulation requires the simultaneous use of several approaches where:\n\nDifferent Bias Sources: Each approach must possess different key sources of potential bias that are uncorrelated with the biases of the other approaches. This ensures that any consistent finding is less likely to be an artefact of a single, shared flaw.\nIncreased Confidence: When the findings from different, methodologically distinct approaches all point to the same conclusion regarding a causal relationship (e.g., exposure \\(A\\) causes outcome \\(B\\)), confidence in that causal finding is significantly increased.\n\n\n\nIdentifying and Addressing Bias\nThe power of triangulation is particularly evident when methodological biases are explicitly considered:\n\nBias Prediction: The approach is strongest when the key sources of bias of some methods (e.g., unmeasured confounding in observational studies, reverse causation in cross-sectional studies) would predict findings that point in opposite directions if those biases were solely responsible for the observed association. Consistency despite these opposing biases provides strong evidence for causality.\nInconsistency as a Guide: When inconsistencies or contradictions arise between the results of different approaches, the triangulation framework provides a mechanism to identify and dissect the key sources of bias inherent in each method. This process then guides researchers to design further, more robust studies to address the causal question.\n\n\n\nApplication in Aetiological Epidemiology\nThe paper illustrates the application of triangulation by combining evidence from a variety of sources to address epidemiological causal questions, including:\n\nConventional Epidemiology: Standard cohort or case-control studies (prone to confounding and reverse causation).\nMendelian Randomization (MR): Genetic association studies that use genetic variants as instrumental variables (less prone to confounding and reverse causation).\nQuasi-experimental designs: Such as sibling comparisons or natural experiments.\nRandomized Controlled Trials (RCTs): The gold standard for causality, often unfeasible or unethical for long-term aetiological questions.\n\nBy integrating evidence across these different methods, triangulation provides a robust framework for overcoming the inherent limitations of any single study design in defining causality."
  },
  {
    "objectID": "statistics/thoresen_2019_30732587.html",
    "href": "statistics/thoresen_2019_30732587.html",
    "title": "Spurious interaction as a result of categorization",
    "section": "",
    "text": "PubMed: 30732587 DOI: 10.1186/s12874-019-0667-2 Overview generated by: Gemini 2.5 Flash, 26/11/2025"
  },
  {
    "objectID": "statistics/thoresen_2019_30732587.html#key-findings-the-generation-of-spurious-interaction",
    "href": "statistics/thoresen_2019_30732587.html#key-findings-the-generation-of-spurious-interaction",
    "title": "Spurious interaction as a result of categorization",
    "section": "Key Findings: The Generation of Spurious Interaction",
    "text": "Key Findings: The Generation of Spurious Interaction\nThis paper presents an additional argument against the common practice in epidemiological and clinical research of converting continuous exposure variables into categorical variables. It demonstrates that such categorization can lead to spurious interaction effects in multiple regression models, even when no true interaction exists between the continuous variables.\nThe spurious interaction problem is fundamentally linked to other well-known issues caused by categorization, including loss of information and statistical power and an increased risk of Type I error if continuous confounder variables are also categorized."
  },
  {
    "objectID": "statistics/thoresen_2019_30732587.html#study-design-and-methods",
    "href": "statistics/thoresen_2019_30732587.html#study-design-and-methods",
    "title": "Spurious interaction as a result of categorization",
    "section": "Study Design and Methods",
    "text": "Study Design and Methods\nThe investigation used a combination of analytical and simulation-based methods:\n\nAnalytical Development\nThe authors derived precise analytical expressions for the linear regression model with two bivariate normally distributed exposure variables (\\(X_1\\) and \\(X_2\\)) and a continuous outcome (\\(Y\\)). Crucially, the true model assumed no interaction between the continuous exposure variables. The analysis then examined the conditions under which an interaction term would appear in a model using the categorized versions (\\(\\tilde{X}_1\\) and \\(\\tilde{X}_2\\)).\n\n\nInterpretation\nThe authors interpret the spurious interaction in two related ways: 1. Measurement Error: Categorization is viewed as an extreme form of differential measurement error. Because the reliability (as measured by the point-biserial correlation) of the categorized variable \\(\\tilde{X}_i\\) varies with the level of the other variable \\(X_j\\), the measurement error is differential, which is known to induce interaction. 2. Residual Confounding: Categorization of a continuous variable leaves residual confounding. Differences in this residual confounding across strata defined by the other exposure variable may lead to the observed spurious interaction."
  },
  {
    "objectID": "statistics/thoresen_2019_30732587.html#results",
    "href": "statistics/thoresen_2019_30732587.html#results",
    "title": "Spurious interaction as a result of categorization",
    "section": "Results",
    "text": "Results\n\nAnalytical Result\nFor two correlated, normally distributed exposure variables, both categorized at the same cut point (\\(c\\)), a spurious interaction term (\\(\\tilde{\\beta}_3\\)) will be induced unless one of two conditions is met: * The two variables are uncorrelated (\\(\\rho=0\\)). * The variables are categorized precisely at the median (\\(c=0\\) in the standardized case).\n\n\nEmpirical Illustrations and Simulation Findings\n\nReal Data Examples: The paper provides two practical examples (one linear model for lung function and one logistic model for myocardial infarction mortality) showing that categorization can change the interpretation of data by generating a statistically significant interaction where the original continuous model showed a non-significant or practically insignificant effect.\nMagnitude: Simulations demonstrated that the magnitude of the induced interaction term (relative to the main effects) increases substantially as the chosen cut point becomes more extreme (further from the median) and as the correlation (\\(\\rho\\)) between the variables increases.\nGeneralizability: Simulations using different distributions (Normal, Uniform, and Chi-square) confirmed that the general effect of spurious interaction due to categorization is present across various distributional shapes."
  },
  {
    "objectID": "statistics/thoresen_2019_30732587.html#conclusions-and-recommendations",
    "href": "statistics/thoresen_2019_30732587.html#conclusions-and-recommendations",
    "title": "Spurious interaction as a result of categorization",
    "section": "Conclusions and Recommendations",
    "text": "Conclusions and Recommendations\nThe primary conclusion is a strong recommendation that the categorization of continuous variables in regression modeling should be avoided.\nThe practice introduces a number of problems, including biased estimates, loss of power, and inflated Type-I error rates, with the generation of spurious interaction being another critical drawback.\nIf an interaction effect is found in an analysis using categorized explanatory variables, the researcher must consider the categorization method itself as a potential and likely explanation for the finding.\nAs alternatives, the authors suggest: * Using non-parametric regression methods if the relationship cannot be easily modeled by classical parametric models. * If one chooses to categorize despite the warnings, it is preferable to categorize into more than two groups to minimize the resulting information loss."
  },
  {
    "objectID": "statistics/altman_2006_16675816.html",
    "href": "statistics/altman_2006_16675816.html",
    "title": "The cost of dichotomising continuous variables",
    "section": "",
    "text": "PubMed: 16675816 DOI: 10.1136/bmj.332.7549.1080 Overview generated by: Gemini 2.5 Flash, 26/11/2025"
  },
  {
    "objectID": "statistics/altman_2006_16675816.html#key-finding-dichotomization-of-continuous-variables-is-statistically-detrimental",
    "href": "statistics/altman_2006_16675816.html#key-finding-dichotomization-of-continuous-variables-is-statistically-detrimental",
    "title": "The cost of dichotomising continuous variables",
    "section": "Key Finding: Dichotomization of Continuous Variables is Statistically Detrimental",
    "text": "Key Finding: Dichotomization of Continuous Variables is Statistically Detrimental\nThis article critiques the common practice in clinical research of converting continuous variables (e.g., blood pressure, weight, cholesterol) into binary categories (dichotomization, e.g., “hypertensive” or “not hypertensive”). The authors argue that while this practice is useful for clinical decision-making and data presentation, it is unnecessary for statistical analysis and introduces several serious, avoidable drawbacks."
  },
  {
    "objectID": "statistics/altman_2006_16675816.html#study-design-and-methods",
    "href": "statistics/altman_2006_16675816.html#study-design-and-methods",
    "title": "The cost of dichotomising continuous variables",
    "section": "Study Design and Methods",
    "text": "Study Design and Methods\nThis paper is a Statistics Note (a commentary/review) that uses theoretical arguments and a review of existing statistical literature to demonstrate the flaws of dichotomization.\nThe core argument is based on quantifying the statistical and inferential costs associated with replacing precise continuous data with a simple binary indicator (0 or 1). The analysis focuses on the detrimental impact on statistical power and Type I error control in subsequent analyses, particularly in regression modeling."
  },
  {
    "objectID": "statistics/altman_2006_16675816.html#results-and-major-drawbacks",
    "href": "statistics/altman_2006_16675816.html#results-and-major-drawbacks",
    "title": "The cost of dichotomising continuous variables",
    "section": "Results and Major Drawbacks",
    "text": "Results and Major Drawbacks\nThe authors identify four main statistical costs associated with dichotomization:\n\n1. Substantial Loss of Statistical Power\nThe primary statistical consequence is a reduction in power to detect a true association or effect. By converting a continuous measure into a binary one, researchers discard a significant amount of information (i.e., the magnitude of a value relative to others). This loss of information is equivalent to conducting a study with a much smaller sample size, making it harder to achieve statistical significance for a genuine effect.\n\n\n2. Inflation of the Type I Error Rate\nWhen a confounding variable is dichotomized in a multivariable model (e.g., logistic regression), it often fails to adequately control for the confounding effect across the full range of the variable. This residual confounding can lead to a substantial inflation of the Type I error rate for other variables in the model, increasing the risk of false-positive findings.\n\n\n3. Arbitrary and Unstable Cut-points\nThe choice of the cut-point used to divide the continuous variable is frequently arbitrary and lacks strong biological justification. Furthermore, attempts to find an “optimal” cut-point based on the observed data are statistically dangerous, as this practice can lead to biased effect estimates (overestimation) and a loss of validity when generalizing results to new data.\n\n\n4. Misleading Effect Estimates\nDichotomization assumes a simple step-function relationship between the variable and the outcome. This ignores the detailed variation within each group and can entirely misrepresent a true biological relationship, especially if that relationship is non-linear across the continuous scale. The resulting effect estimate only represents the difference between the mean values of the two resulting groups, masking the true dose-response curve."
  },
  {
    "objectID": "statistics/altman_2006_16675816.html#conclusion-and-recommendations",
    "href": "statistics/altman_2006_16675816.html#conclusion-and-recommendations",
    "title": "The cost of dichotomising continuous variables",
    "section": "Conclusion and Recommendations",
    "text": "Conclusion and Recommendations\nThe authors conclude that dichotomization sacrifices statistical rigor for an unnecessary simplicity in the analysis stage.\nThey strongly recommend that continuous variables should be analyzed on their original continuous scale in statistical models (e.g., as continuous predictors in regression models). If the relationship is suspected to be non-linear, more appropriate methods such as fractional polynomials or splines should be used instead of categorization."
  },
  {
    "objectID": "statistics/sterne_2001_11159626.html",
    "href": "statistics/sterne_2001_11159626.html",
    "title": "Sifting the evidence—what’s wrong with significance tests?",
    "section": "",
    "text": "PubMed: 11159626 DOI: 10.1136/bmj.322.7280.226 Overview generated by: Gemini 2.5 Flash, 26/11/2025"
  },
  {
    "objectID": "statistics/sterne_2001_11159626.html#key-findings-the-misuse-and-limitations-of-statistical-significance",
    "href": "statistics/sterne_2001_11159626.html#key-findings-the-misuse-and-limitations-of-statistical-significance",
    "title": "Sifting the evidence—what’s wrong with significance tests?",
    "section": "Key Findings: The Misuse and Limitations of Statistical Significance",
    "text": "Key Findings: The Misuse and Limitations of Statistical Significance\nThis highly influential article critiques the over-reliance on statistical significance testing (p-values) in medical and epidemiological research, arguing that this practice fundamentally distorts the scientific literature and leads to public skepticism.\n\nThe Central Problem: Publication Bias\nThe primary issue is the medical literature’s strong tendency to accentuate the positive, leading to publication bias (also known as the “file drawer effect”):\n\nSkewed Reporting: Studies with positive outcomes (those achieving statistical significance, typically P&lt;0.05) are far more likely to be published than those with null results (non-significant findings).\nIncreased Chance Findings: This creates a system where a host of purely chance findings are published and subsequently mistaken for real biological or clinical effects. The authors note that, by conventional reasoning, examining 20 associations will produce one “significant at P=0.05” result by chance alone.\nErosion of Trust: The proliferation of inconsistent, purely chance findings contributes significantly to scepticism about medical research and epidemiological studies among the public and practitioners.\n\n\n\nShifting Focus: From P-value to Effect Magnitude\nThe authors argue that focusing solely on whether a P-value crosses the 0.05 threshold misses the point of much medical research, particularly in observational and interventional studies:\n\nNull Hypothesis Relevance: In many epidemiological studies and randomized controlled trials, there is often little reason to expect the true effect to be exactly null. The key issue is not consistency with a strict null hypothesis.\nThe Real Questions: Instead of asking if an effect exists (P-value), researchers should focus on:\n\nWhether the direction of the effect has been reasonably and firmly established.\nWhether the magnitude of the effect is such that it is of public health or clinical importance. A small, statistically significant effect may be clinically irrelevant. A large, non-significant effect may warrant further study.\n\n\n\n\nHistorical Context\nThe critique is contextualized by referencing the founder of statistical significance testing, Ronald Fisher, and the early criticism he received from his colleague F. Yates, who noted that Fisher’s emphasis on significance testing was problematic. The paper implicitly advocates for the use of Confidence Intervals (CIs), which convey both the direction and the magnitude of the effect along with the precision of the estimate."
  },
  {
    "objectID": "statistics/ciolino_2013_24138438.html",
    "href": "statistics/ciolino_2013_24138438.html",
    "title": "Covariate Imbalance and Adjustment for Logistic Regression Analysis of Clinical Trial Data",
    "section": "",
    "text": "PubMed: 24138438 DOI: 10.1080/10543406.2013.834912 Overview generated by: Gemini 2.5 Flash, 26/11/2025"
  },
  {
    "objectID": "statistics/ciolino_2013_24138438.html#key-findings-the-necessity-of-covariate-adjustment-in-logistic-regression",
    "href": "statistics/ciolino_2013_24138438.html#key-findings-the-necessity-of-covariate-adjustment-in-logistic-regression",
    "title": "Covariate Imbalance and Adjustment for Logistic Regression Analysis of Clinical Trial Data",
    "section": "Key Findings: The Necessity of Covariate Adjustment in Logistic Regression",
    "text": "Key Findings: The Necessity of Covariate Adjustment in Logistic Regression\nThis paper uses simulation to quantify the benefits of covariate adjustment in the analysis of randomized controlled trials (RCTs) with a binary outcome, specifically focusing on models using logistic regression. The findings highlight that, unlike linear regression, unadjusted and adjusted treatment effect estimates in logistic regression are generally not equivalent, making adjustment a necessary step for precise inference.\n\nInequivalence of Adjusted vs. Unadjusted Estimates\nThe central statistical problem addressed is the non-collapsibility of the Odds Ratio (OR) in logistic regression:\n\nUnadjusted Bias: In the presence of influential covariates, the unadjusted OR (which estimates the marginal effect) is typically a biased estimate of the conditional OR (the effect after controlling for covariates), even if the groups are perfectly balanced due to randomization.\nImpact of Imbalance: While randomization ensures that any imbalance is due to chance, the presence of an influential, imbalanced covariate can further exacerbate the difference between the marginal (unadjusted) and conditional (adjusted) treatment effects.\n\n\n\nQuantifying the Benefit of Adjustment\nThe simulation study quantified the statistical benefits of using adjusted analysis:\n\nIncreased Power: Adjusting for important prognostic covariates significantly increases statistical power to detect a true treatment effect. Simulations demonstrated power benefits of up to 17.5% for log-normally distributed covariates and up to 9.4% for normally distributed covariates when the covariate effect was strong.\nReduced Bias: Adjustment helps reduce the bias of the treatment effect estimate with respect to the conditional treatment effect (the effect being targeted in the adjusted model).\n\n\n\nRecommendations for Clinical Trial Analysis\nThe authors reinforce established guidelines and provide practical advice for analysis:\n\nPre-specification: Following International Conference on Harmonization (ICH) guidelines, covariate adjustment should be pre-specified in the study protocol. Unplanned adjustments should be considered secondary analyses.\nBalance is Not Enough: If adjustment is not possible or unplanned, achieving strong baseline balance in continuous covariates can mitigate some of the shortcomings (lower power, greater potential for bias) of unadjusted analyses, but it cannot fully eliminate the inherent difference between the marginal and conditional ORs due to the non-collapsibility of the logistic model.\nFocus on Efficiency: The primary reason for adjustment is not to correct a failure of randomization, but to increase the efficiency (power) of the analysis by accounting for known sources of variation in the outcome."
  },
  {
    "objectID": "statistics/wasserstein_2019_1583913.html",
    "href": "statistics/wasserstein_2019_1583913.html",
    "title": "Moving to a World Beyond \\(p < 0.05\\)",
    "section": "",
    "text": "PubMed: Not Indexed (The American Statistician) DOI: 10.1080/00031305.2019.1583913 Overview generated by: Gemini 2.5 Flash, 26/11/2025"
  },
  {
    "objectID": "statistics/wasserstein_2019_1583913.html#key-findings-the-case-against-dichotomous-statistical-significance",
    "href": "statistics/wasserstein_2019_1583913.html#key-findings-the-case-against-dichotomous-statistical-significance",
    "title": "Moving to a World Beyond \\(p < 0.05\\)",
    "section": "Key Findings: The Case Against Dichotomous Statistical Significance",
    "text": "Key Findings: The Case Against Dichotomous Statistical Significance\nThis highly influential editorial, which introduced a special issue of The American Statistician containing 43 papers on the topic, marks a critical step in the statistical community’s effort to reform scientific practice. It explicitly calls for an end to the culture of dichotomous thinking based solely on the threshold of \\(p &lt; 0.05\\). The authors argue that declaring a result “statistically significant” based on an arbitrary cutoff is counterproductive and has fueled the reproducibility crisis.\n\nThe Problem with Dichotomization\nThe fundamental issue lies in the over-simplification of complex statistical results into a binary “significant/non-significant” outcome:\n\nArbitrary Cutoff: The \\(p &lt; 0.05\\) threshold is arbitrary. Treating a \\(p=0.049\\) result as fundamentally different from a \\(p=0.051\\) result leads to illogical conclusions and flawed decision-making.\nExaggerated Confidence: Declaring a result “statistically significant” implies a certainty or importance that the p-value alone does not justify. It often leads researchers and the public to mistake statistical significance for scientific or clinical importance.\nFueling Bias: The dichotomous framework is the root cause of poor research practices like P-hacking (data-dependent manipulation to cross the threshold) and publication bias (selective reporting of results that pass the threshold). These biases inflate the true rate of false positives in the literature.\n\n\n\nThe Solution: Embracing a Continuous View of Evidence\nThe authors propose a simple, yet profound, shift in reporting and thinking:\n\nAbandon “Statistical Significance”: The term “statistically significant” and its binary cousin “non-significant” should be retired from scientific discourse.\nFocus on Compatibility: Researchers should instead report the p-value as a measure of incompatibility between the data and the assumed statistical model (usually the null hypothesis). They must interpret this value continuously, considering the p-value’s proximity to zero as a gradient of evidence against the null.\nEmphasize Magnitude and Precision: The core focus of reporting should be on the effect size and its uncertainty, which is best communicated via Confidence Intervals (CIs) or Credible Intervals (from Bayesian analysis). CIs show the range of plausible effects compatible with the data.\nIntegrate Context: Conclusions must be based on the entirety of the evidence, including the context of the research, the quality of the study design, external knowledge, and the costs/benefits of potential actions, not just the p-value.\n\n\n\nThe Role of Prediction Intervals and False Discovery Rates\nThe article encourages the use of various other tools that provide a more complete picture of the evidence, such as:\n\nPrediction Intervals: Show the range of values expected for a future observation.\nFalse Discovery Rates (FDR) and False Positive Risks (FPR): Help quantify the probability that a “significant” finding is actually false, which is often much higher than the p-value suggests.\n\nThe statement concludes by asserting that the scientific community needs to move toward a “post p &lt; 0.05 era” where thoughtful interpretation replaces rigid decision rules."
  },
  {
    "objectID": "statistics/wasserstein_2016_26820252.html",
    "href": "statistics/wasserstein_2016_26820252.html",
    "title": "The ASA’s Statement on p-Values: Context, Process, and Purpose",
    "section": "",
    "text": "DOI: 10.1080/00031305.2016.1154108 Overview generated by: Gemini 2.5 Flash, 26/11/2025"
  },
  {
    "objectID": "statistics/wasserstein_2016_26820252.html#key-findings-principles-for-the-proper-use-of-the-p-value",
    "href": "statistics/wasserstein_2016_26820252.html#key-findings-principles-for-the-proper-use-of-the-p-value",
    "title": "The ASA’s Statement on p-Values: Context, Process, and Purpose",
    "section": "Key Findings: Principles for the Proper Use of the p-Value",
    "text": "Key Findings: Principles for the Proper Use of the p-Value\nThis article presents and explains the American Statistical Association’s (ASA) Statement on p-Values and Statistical Significance, the first-ever policy statement from the ASA specifically addressing a foundational issue of statistical inference. The statement was prompted by the widespread misuse and misinterpretation of the p-value across all fields of science, which contributes to the crisis of irreproducible research.\n\nSix Core Principles for p-Values\nThe statement outlines six key principles, aiming to promote better practice and curb common errors:\n\nP-values can indicate how incompatible the data are with a specified statistical model.\n\nThe p-value measures the incompatibility between the data and the assumed statistical model (usually the null hypothesis). A small p-value indicates that the data are unlikely under the null model.\n\nP-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone.\n\nThis directly addresses the most common and disastrous misinterpretation: that a low p-value (e.g., P=0.01) means the null hypothesis has only a 1% chance of being true. P-values relate to data given the model, not the probability of the model given the data.\n\nScientific conclusions and business or policy decisions should not be based only on whether a p-value passes a specific threshold.\n\nThe ASA strongly discourages the practice of dichotomizing results into “statistically significant” and “not statistically significant.” This threshold thinking can lead to flawed decisions, ignoring the importance of effect size, context, and other evidence.\n\nProper inference requires full reporting and transparency.\n\nThe selective reporting of only “significant” results (known as P-hacking or publication bias) renders the reported p-values meaningless. All analyses, assumptions, and findings, regardless of the p-value, must be disclosed.\n\nA p-value, or statistical significance, does not measure the size of an effect or the importance of a result.\n\nStatistical significance is often confused with substantive (clinical, practical, or scientific) importance. A very large study can produce a statistically significant p-value for a trivial effect, while a small study might fail to find significance for a massive, important effect. The focus should be on effect magnitude.\n\nBy itself, a p-value does not provide a good measure of evidence regarding a model or hypothesis.\n\nScientific reasoning requires more than just a p-value. It demands contextual knowledge, common sense, study design quality, data reliability, and integration with external evidence. Other statistical measures, particularly Confidence Intervals (CIs) and Bayesian methods, should be used to provide a richer understanding of the evidence.\n\n\n\n\nPurpose of the Statement\nThe statement is not intended to be a simple replacement for null hypothesis significance testing, but rather a step toward a “post p&lt;0.05 era” where statistical methods are used more thoughtfully. It calls for a move toward better scientific practice characterized by open communication, transparent methodology, and a focus on effect size, precision (CIs), and context."
  },
  {
    "objectID": "proteomics.html",
    "href": "proteomics.html",
    "title": "Proteomics",
    "section": "",
    "text": "test\ntest"
  },
  {
    "objectID": "pgs.html",
    "href": "pgs.html",
    "title": "polygenic scores",
    "section": "",
    "text": "Genetic prediction of complex traits with polygenic scores: A statistical review\n\nThis statistical review comprehensively analyzes 46 methods for Polygenic Score (PGS) construction, unifying most of them under a multiple linear regression framework to clarify their assumptions regarding effect size distribution and Linkage Disequilibrium (LD).\nThe review concludes that optimal PGS performance (accuracy) is highly dependent on the trait’s genetic architecture and is significantly improved by using Bayesian/Regularization methods (e.g., LDpred, PRS-CS) that explicitly model LD and incorporate informed prior distributions for SNP effects.\nA critical challenge highlighted is the significant loss of transferability across ancestral populations, underscoring the need for more diverse training data and methods that better address ancestral heterogeneity and incorporate non-additive and Gene-by-Environment (GxE) effects.\n\n\n\nGenome-wide risk prediction of common diseases across ancestries in one million people\n\nThis large-scale study evaluated the cross-ancestry transferability of Polygenic Risk Scores (PRSs) for four common diseases (CAD, T2D, breast, and prostate cancer) using data from six biobanks and over one million individuals of diverse global ancestries.\nThe analysis found that PRS transferability was high and robust across different populations and substructures of European ancestry, but was significantly lower for individuals of African, South Asian, and East Asian ancestry.\nThe poor transferability, which was most pronounced in African ancestry individuals, highlights the critical issue of ancestral bias in genomic research and the potential for current PRS implementation to exacerbate health disparities until more diverse training data are available.\n\n\n\nPolygenic scoring accuracy varies across the genetic ancestry continuum\n\nCore Principle: This landmark study challenged the traditional use of discrete ancestry groups for polygenic scores (PGSs), proposing a framework that evaluates individual-level PGS accuracy based on Genetic Distance (GD) from the GWAS training population.\nKey Finding: They demonstrated that individual-level PGS accuracy experiences a continuous, steep decay as GD from the training data increases, with an average Pearson correlation of R = -0.95 across 84 complex traits, confirming that performance loss is a predictable function of genetic dissimilarity.\nHealth Equity Implication: The study quantified a major health disparity, showing that the genetically closest individuals of non-European ancestry (e.g., Hispanic/Latino American) had PGS accuracy comparable to the most distant European-ancestry individuals, highlighting the severe and systematic bias due to lack of diversity in training cohorts.\nRecommendation: The authors advocate for moving beyond discrete ancestry labels and using continuous metrics like GD to characterize and correct for performance disparities, thus ensuring more equitable clinical translation of PGSs.\n\n\n\nDefining type 2 diabetes polygenic risk scores through colocalization and network-based clustering of metabolic trait genetic associations\n\nCore Principle: This study partitioned the genetic heterogeneity of Type 2 Diabetes (T2D) using a novel colocalization-first approach followed by network-based clustering of T2D and 20 related metabolic traits across 243 loci.\nKey Finding: The method identified five distinct T2D biological pathways (Obesity, Lipodystrophic insulin resistance, Liver/lipid metabolism, Hepatic glucose metabolism, and Beta-cell dysfunction), successfully isolating genetically distinct disease mechanisms.\nClinical Significance: Partitioned Polygenic Risk Scores (PRSs) showed heterogeneous clinical associations in a validation cohort (n=21,742 T2D individuals); notably, the Lipodystrophic insulin resistance PRS and Beta-cell dysfunction PRS were causally associated with lower BMI, providing genetic validation for the clinically important “lean diabetes” sub-type.\nMethodological Advance: By integrating colocalization and Mendelian Randomization, the framework provided stronger inferences on the causality and directionality of the genetic associations, which is essential for translating genetic discoveries into targeted T2D treatments."
  },
  {
    "objectID": "pgs/ma_2021_34243982.html",
    "href": "pgs/ma_2021_34243982.html",
    "title": "Genetic prediction of complex traits with polygenic scores: A statistical review",
    "section": "",
    "text": "PubMed: 34243982\nDOI: 10.1016/j.tig.2021.06.004\nOverview generated by: Gemini 2.5 Flash, 26/11/2025"
  },
  {
    "objectID": "pgs/ma_2021_34243982.html#key-findings",
    "href": "pgs/ma_2021_34243982.html#key-findings",
    "title": "Genetic prediction of complex traits with polygenic scores: A statistical review",
    "section": "Key Findings",
    "text": "Key Findings\nThis comprehensive statistical review provides an exhaustive analysis of the landscape of Polygenic Score (PGS) methods, a critical area in human genetics focused on predicting complex traits and disease risk using genetic data. The authors review 46 different methods for PGS construction, establishing a unifying multiple linear regression framework to connect and categorize the majority of these techniques. The core conclusion is that the optimal PGS method is highly dependent on the genetic architecture of the target trait (e.g., polygenicity, effect size distribution) and the nature of the available training and target data. The review serves as an essential reference, providing both the statistical underpinnings for method developers and practical guidance (including a decision tree) for analysts performing PGS analysis in clinical and research settings."
  },
  {
    "objectID": "pgs/ma_2021_34243982.html#categorization-and-statistical-framework",
    "href": "pgs/ma_2021_34243982.html#categorization-and-statistical-framework",
    "title": "Genetic prediction of complex traits with polygenic scores: A statistical review",
    "section": "Categorization and Statistical Framework",
    "text": "Categorization and Statistical Framework\nThe review structures the diverse landscape of PGS methods into a coherent statistical framework, primarily centered on how they estimate the SNP effect sizes, which serve as the weights for the Polygenic Score.\n\nCore PGS Calculation\nIn its simplest form, the PGS for an individual (\\(i\\)) is a weighted sum of their genotypes across \\(M\\) single nucleotide polymorphisms (SNPs): \\[\\text{PGS}_i = \\sum_{j=1}^{M} G_{ij} \\hat{\\beta}_j\\] where \\(G_{ij}\\) is the genotype of individual \\(i\\) at SNP \\(j\\), and \\(\\hat{\\beta}_j\\) is the estimated genetic effect size (the weight) for that SNP.\n\n\nUnifying Multiple Linear Regression Framework\nThe authors classify most modern PGS methods as variants of a general multiple linear regression model: \\[\\mathbf{Y} = \\mathbf{G}\\mathbf{\\beta} + \\mathbf{\\epsilon}\\] where \\(\\mathbf{Y}\\) is the phenotype vector, \\(\\mathbf{G}\\) is the genotype matrix, \\(\\mathbf{\\beta}\\) is the vector of true genetic effects, and \\(\\mathbf{\\epsilon}\\) is the error term. Different PGS methods (e.g., LDpred, S-Bayes) are distinguished by their assumptions about the effect size vector, \\(\\mathbf{\\beta}\\), and how they account for the correlation structure of the genotypes (Linkage Disequilibrium or LD).\n\n\nClassification of PGS Methods\nThe review categorizes the 46 analyzed methods based on their underlying statistical approach:\n\nClassical Methods: These include P-value Thresholding and Clumping (P+T), which selects a subset of independent SNPs based on their p-values. This remains a simple and surprisingly effective baseline method.\nBayesian and Regularization Methods: These methods explicitly model the genetic architecture by incorporating prior distributions on the SNP effect sizes (\\(\\mathbf{\\beta}\\)) and/or regularizing the estimates to account for noise and LD. Examples include:\n\nLDpred/LDpred2: Assumes a fraction of SNPs are causal and uses an LD reference panel to shrink effect sizes.\nBayesC/BayesR: Assumes effect sizes come from a mixture of normal distributions, allowing for a few large effects and many small ones.\nLasso/Ridge Regression: Uses penalization to optimize effect size selection and estimation.\n\nSummary Statistics-Based Methods: Methods that operate entirely on GWAS summary statistics and an external LD reference panel (e.g., LDpred, S-Bayes, PRS-CS). These are the most computationally efficient and widely used due to data sharing conventions.\nMeta-Dimensional Methods: These include methods that incorporate information beyond SNP effects, such as functional annotations or gene expression data (e.g., MetaXcan)."
  },
  {
    "objectID": "pgs/ma_2021_34243982.html#practical-considerations-and-performance",
    "href": "pgs/ma_2021_34243982.html#practical-considerations-and-performance",
    "title": "Genetic prediction of complex traits with polygenic scores: A statistical review",
    "section": "Practical Considerations and Performance",
    "text": "Practical Considerations and Performance\n\nFactors Affecting PGS Performance\nThe prediction accuracy of a PGS (typically measured by the coefficient of determination, \\(R^2\\)) is highly sensitive to several factors:\n\nGenetic Architecture: Methods that accurately model the true genetic architecture (e.g., high polygenicity vs. oligenicity) perform best. Bayesian methods often excel because they flexibly model the prior distribution of effect sizes.\nTraining Sample Size: Performance is highly dependent on the size of the GWAS used to estimate \\(\\hat{\\beta}\\). Larger sample sizes generally lead to more accurate effect size estimates and thus better PGS performance.\nAncestral Divergence: Prediction accuracy significantly drops when the target population ancestry differs substantially from the training population (e.g., GWAS conducted primarily in European populations but applied to African populations). This highlights the critical issue of transferability and health equity.\nLinkage Disequilibrium (LD) Modeling: Explicitly accounting for LD, such as in LDpred and PRS-CS, is crucial for improving prediction accuracy compared to simple methods like P+T.\n\n\n\nDecision Tree for PGS Analysis\nThe review provides a practical decision tree to help researchers select the appropriate PGS method based on the available data and research question:\nKey branches include: * Input Data: Is individual-level data or only GWAS summary data available? * Trait Complexity: Analyzing a single trait or multiple correlated traits? * Modeling Approach: Choosing between model-based (e.g., linear mixed models) and algorithm-based (e.g., machine learning) methods."
  },
  {
    "objectID": "pgs/ma_2021_34243982.html#challenges-and-future-directions",
    "href": "pgs/ma_2021_34243982.html#challenges-and-future-directions",
    "title": "Genetic prediction of complex traits with polygenic scores: A statistical review",
    "section": "Challenges and Future Directions",
    "text": "Challenges and Future Directions\nThe authors identify several major challenges that need to be addressed to realize the full clinical potential of PGS:\n\nAddressing Heterogeneity (Ancestry): Developing methods that maintain high predictive accuracy across diverse ancestral populations and that can properly perform multi-ancestry meta-analysis to generate universally accurate PGS.\nNon-Additive and GxE Effects: Incorporating non-additive genetic effects (dominance, epistasis) and Gene-by-Environment (GxE) interactions into the PGS model. Current models are largely additive and thus leave substantial variance unexplained.\nCausal Variants and Fine-Mapping: Moving beyond marker SNPs to accurately identify and weight the true causal variants to improve biological relevance and prediction.\nClinical Implementation: Establishing standardized reporting guidelines, validating PGS in independent clinical cohorts, and addressing the ethical concerns related to using PGS in personalized medicine."
  },
  {
    "objectID": "pgs/ghatan_2024_38200577.html",
    "href": "pgs/ghatan_2024_38200577.html",
    "title": "Defining type 2 diabetes polygenic risk scores through colocalization and network-based clustering of metabolic trait genetic associations",
    "section": "",
    "text": "PubMed: 38200577 DOI: 10.1186/s13073-023-01255-7 Overview generated by: Gemini 2.5 Flash, 26/11/2025"
  },
  {
    "objectID": "pgs/ghatan_2024_38200577.html#key-findings-dissecting-t2d-heterogeneity-via-pleiotropy",
    "href": "pgs/ghatan_2024_38200577.html#key-findings-dissecting-t2d-heterogeneity-via-pleiotropy",
    "title": "Defining type 2 diabetes polygenic risk scores through colocalization and network-based clustering of metabolic trait genetic associations",
    "section": "Key Findings: Dissecting T2D Heterogeneity via Pleiotropy",
    "text": "Key Findings: Dissecting T2D Heterogeneity via Pleiotropy\nThis study addresses the profound genetic and clinical heterogeneity of Type 2 Diabetes (T2D) by developing a refined framework to partition T2D-associated genetic variants into distinct biological pathways. The goal is to move beyond a single, monolithic T2D diagnosis toward stratified risk prediction and targeted therapeutic strategies. The method leverages the pleiotropic nature of genetic variants—their influence on multiple related traits—to define distinct mechanisms of T2D pathogenesis.\n\nColocalization-First Partitioning and Clustering\nThe authors improved upon previous clustering approaches by integrating rigorous statistical checks for shared causality, enhancing the mechanistic interpretability of the resulting risk scores.\n\nColocalization Analysis: They applied colocalization analysis between T2D and 20 related metabolic traits (selected based on established risk factors and genetic correlation) across 243 T2D loci. This step robustly identified 146 T2D loci where the T2D association was likely caused by the same causal variant as the associated metabolic trait.\nNetwork-Based Clustering: A network-based unsupervised hierarchical clustering approach was then performed using the colocalized variant-trait associations. This successfully grouped the T2D risk loci into five distinct clusters, each representing a unique, interconnected set of T2D and metabolic risk factors.\nCausality Check (Mendelian Randomization): The study explicitly assessed the causality and directionality of the variant-trait associations using the Mendelian randomization (MR) Steiger’s Z-test. This confirmed that the genetic associations identified in the clusters were largely causal for the corresponding metabolic phenotypes.\n\n\n\nFive Distinct T2D Pathophysiological Clusters\nThe five identified genetic clusters, which align with distinct T2D pathophysiologies, are: 1. Obesity (High BMI-T2D risk) 2. Lipodystrophic insulin resistance (T2D risk associated with fat distribution/dysfunction) 3. Liver and lipid metabolism 4. Hepatic glucose metabolism 5. Beta-cell dysfunction (Impaired insulin secretion)\n\n\nHeterogeneous Clinical Profiles and “Lean Diabetes”\nPartitioned Polygenic Risk Scores (PRSs) were generated for each cluster and externally validated in 21,742 individuals with T2D across three independent cohorts, demonstrating unique associations with metabolic and clinical outcomes:\n\nOpposite BMI Associations: The Obesity PRS was strongly associated with a higher BMI, as expected. Critically, the Lipodystrophic insulin resistance PRS and Beta-cell dysfunction PRS were both associated with lower BMI.\nSupport for Lean Diabetes: The MR Steiger analysis provided causal evidence that increased T2D risk in the lipodystrophic insulin resistance and beta-cell dysfunction pathways was causally associated with lower BMI. This provides a genetic foundation for the “lean diabetes” or non-obese T2D sub-type, where risk is driven by dysfunctional fat/insulin-secretion rather than overall fat mass.\nComorbidity Stratification: The Lipodystrophic insulin resistance PRS was uniquely and specifically associated with a higher odds of chronic kidney disease (CKD) (Odds Ratio 1.29), suggesting that individuals whose T2D risk is driven by this pathway may require specific monitoring and intervention for renal complications.\n\n\n\nConclusion\nThe colocalization-first, network-based clustering methodology successfully and robustly partitioned the genetic heterogeneity underlying T2D. The resulting pathway-specific PRSs provide valuable tools for risk stratification, sub-type identification, and the development of targeted therapies based on an individual’s distinct genetic mechanism of disease."
  },
  {
    "objectID": "metabolomics.html",
    "href": "metabolomics.html",
    "title": "metabolomics",
    "section": "",
    "text": "test\ntest"
  },
  {
    "objectID": "genetics/timpson_2017_29225335.html",
    "href": "genetics/timpson_2017_29225335.html",
    "title": "Genetic architecture: the shape of the genetic contribution to human traits and disease",
    "section": "",
    "text": "PubMed: 29225335\nDOI: 10.1038/nrg.2017.101\nOverview generated by: Gemini 2.5 Flash, 26/11/2025"
  },
  {
    "objectID": "genetics/timpson_2017_29225335.html#key-findings",
    "href": "genetics/timpson_2017_29225335.html#key-findings",
    "title": "Genetic architecture: the shape of the genetic contribution to human traits and disease",
    "section": "Key Findings",
    "text": "Key Findings\nThis comprehensive review synthesizes the field’s understanding of genetic architecture—the characteristics of genetic variation responsible for heritable phenotypic variability—in the era following the advent of large-scale Genome-Wide Association Studies (GWAS) and Next-Generation Sequencing (NGS). The authors systematically define the components of genetic architecture and explain how recent technological advances have begun to reveal the complex interplay of factors contributing to human traits and diseases.\n\nCore Components of Genetic Architecture\nThe genetic architecture of any complex trait is defined by four interacting components, which the review explores in depth:\n\nNumber of Causal Variants: The sheer count of genetic variants (SNPs, indels, SVs) that collectively affect the trait. Most complex traits are highly polygenic, involving thousands of variants.\nEffect Size Distribution: The magnitude of the effect that each variant contributes to the phenotype. GWAS has revealed that many common variants have small, additive effects, while rare variants often have large effects.\nAllele Frequency Spectrum: The distribution of causal variant frequencies in the population. Common traits are often influenced by variants across the entire frequency spectrum, supporting the ‘common disease, common variant’ and ‘common disease, rare variant’ hypotheses in tandem.\nInteractions: The complexity added by non-additive relationships:\n\nAllelic Interactions: Dominance (interaction between alleles at the same locus).\nLocus Interactions: Epistasis (interaction between alleles at different loci).\nEnvironmental Interactions: Gene-by-Environment (GxE) interaction."
  },
  {
    "objectID": "genetics/timpson_2017_29225335.html#impact-of-modern-genomic-technologies-on-architecture-discovery",
    "href": "genetics/timpson_2017_29225335.html#impact-of-modern-genomic-technologies-on-architecture-discovery",
    "title": "Genetic architecture: the shape of the genetic contribution to human traits and disease",
    "section": "Impact of Modern Genomic Technologies on Architecture Discovery",
    "text": "Impact of Modern Genomic Technologies on Architecture Discovery\nThe review highlights how different technologies have been instrumental in characterizing specific aspects of the genetic architecture:\n\nGWAS and Common Variant Architecture\n\nGWAS Success: GWAS has been highly successful in identifying thousands of common, low-effect variants for hundreds of traits, confirming the extreme polygenicity of complex traits.\nMissing Heritability: The review addresses the historical problem of “missing heritability”—the gap between heritability estimated from twin/family studies (broad-sense heritability) and that explained by all detected common SNPs (SNP-heritability). Explanations include:\n\nThe contribution of rare variants missed by GWAS arrays.\nThe residual influence of non-additive effects (dominance and epistasis) captured by family studies but not fully by linear GWAS models.\nThe contribution of structural variation and gene-environment interactions.\n\nLocus Heterogeneity: GWAS often reveals multiple independent associated signals within the same locus, indicating allelic series or complex local regulation.\n\n\n\nNext-Generation Sequencing (NGS) and Rare Variants\n\nSequencing Role: NGS studies (e.g., whole-exome sequencing, whole-genome sequencing) are essential for characterizing the role of rare variants.\nBurden Tests: These tests aggregate the effects of multiple rare variants within a single gene or region. The review notes that rare, high-penetrance variants often reside in genes under strong negative selection, explaining why their overall contribution to population variance (though individually large) may be limited.\nClinical Relevance: Rare variants are crucial for understanding Mendelian disease and for identifying genes with large effects that are strong candidates for drug targets."
  },
  {
    "objectID": "genetics/timpson_2017_29225335.html#complexity-of-genetic-effects",
    "href": "genetics/timpson_2017_29225335.html#complexity-of-genetic-effects",
    "title": "Genetic architecture: the shape of the genetic contribution to human traits and disease",
    "section": "Complexity of Genetic Effects",
    "text": "Complexity of Genetic Effects\n\nPleiotropy and Shared Genetic Etiology\n\nWidespread Pleiotropy: The authors emphasize that pleiotropy (a single genetic variant affecting multiple distinct traits) is the norm, not the exception, for common variants identified by GWAS. This is supported by analyses showing extensive genetic correlation between traits.\nConfounding: Pleiotropy complicates causal inference. The review discusses how techniques like Mendelian Randomization (MR) are used to distinguish true causal effects from horizontal pleiotropy (a single variant affecting multiple outcomes through different pathways).\n\n\n\nGene-Environment (GxE) Interactions\n\nDefinition: GxE occurs when the effect of a genetic variant on a phenotype depends on the individual’s environment (e.g., diet, smoking, stress).\nDetection Challenge: GxE interactions are notoriously difficult to detect and estimate accurately due to requiring large samples with precise environmental measures. The review notes that population-based cohorts like the UK Biobank are vital for making progress in this area."
  },
  {
    "objectID": "genetics/timpson_2017_29225335.html#future-directions-and-clinical-goals",
    "href": "genetics/timpson_2017_29225335.html#future-directions-and-clinical-goals",
    "title": "Genetic architecture: the shape of the genetic contribution to human traits and disease",
    "section": "Future Directions and Clinical Goals",
    "text": "Future Directions and Clinical Goals\nThe review concludes by outlining the necessary steps to fully characterize genetic architecture and achieve the field’s clinical goals:\n\nComprehensive Mapping: Moving from association studies to causal variant identification, focusing on non-coding variants and improving fine-mapping methods.\nAccounting for Non-Additivity: Developing statistical methods that are better powered to detect and estimate dominance and epistatic effects in large cohorts.\nIntegrating Environment: Robustly incorporating environmental exposure data into models to quantify the contribution of GxE interactions and improve personalized risk prediction.\nClinical Translation: Leveraging the understanding of genetic architecture to improve disease screening, diagnosis, prognosis, and therapeutic development. This includes prioritizing genes for drug development based on the magnitude and specificity of their genetic effects."
  },
  {
    "objectID": "genetics/dewalsche_2025_39792927.html",
    "href": "genetics/dewalsche_2025_39792927.html",
    "title": "metaGE: Investigating genotype x environment interactions through GWAS meta-analysis",
    "section": "",
    "text": "PubMed: 39792927\nDOI: 10.1371/journal.pgen.1011553\nOverview generated by: Claude Sonnet 4.5, 25/11/2025"
  },
  {
    "objectID": "genetics/dewalsche_2025_39792927.html#key-findings",
    "href": "genetics/dewalsche_2025_39792927.html#key-findings",
    "title": "metaGE: Investigating genotype x environment interactions through GWAS meta-analysis",
    "section": "Key Findings",
    "text": "Key Findings\nThis study introduces metaGE, a meta-analysis approach for detecting quantitative trait loci (QTL) in multi-environment trial (MET) experiments by jointly analyzing summary statistics from individual environment GWAS, addressing the challenge of genotype-by-environment (GxE) interactions in plant genetics.\n\nMain Discoveries\n\nSuperior Type I error control: metaGE effectively controls false discovery rate (FDR ≤ 0.05) across simulated scenarios, while competing methods (METAL, mash) show severe inflation (FDR &gt; 0.84)\nComputational efficiency: Analyzes large-scale datasets (22 environments × 600K markers) in ~2 minutes, dramatically faster than existing mixed-model approaches\nNovel QTL detection: Identified new loci in Arabidopsis (competition-responsive flowering QTLs) and maize (heat-stress responsive yield QTLs) not detected by original single-environment analyses\nFlexible testing framework: Enables detection of QTLs with stable effects, environment-specific effects, or effects correlated with environmental covariates"
  },
  {
    "objectID": "genetics/dewalsche_2025_39792927.html#study-design",
    "href": "genetics/dewalsche_2025_39792927.html#study-design",
    "title": "metaGE: Investigating genotype x environment interactions through GWAS meta-analysis",
    "section": "Study Design",
    "text": "Study Design\n\nMethodological Framework\nmetaGE jointly analyzes summary statistics (effect sizes and P-values) from per-environment GWAS without requiring raw phenotypic or genotypic data.\nKey innovations: - Accounts for inter-environment correlations arising from overlapping genotype panels - Supports both controlled (fixed-effect) and uncontrolled (random-effect) environments - Includes meta-regression to detect QTL-environment covariate relationships\n\n\nStatistical Models\nZ-score transformation: \\[Z_{mk} = \\Phi^{-1}(0.5 \\cdot p_{mk}) \\times \\text{sign}(\\beta_{mk})\\]\nwhere β_mk is the marker effect and p_mk is the P-value for marker m in environment k.\nFixed Effect (FE) Model (controlled environments): \\[Z_m = X\\mu_m + E_m\\] \\[E_m \\sim N(0_K, \\Sigma_m)\\]\n\nEnvironments classified into J groups with stable effects within groups\nTests for marker association: H₀: {μ_m = 0_J} vs H₁: {∃j, μ^j_m ≠ 0}\nTests for effect heterogeneity across groups\n\nRandom Effect (RE) Model (uncontrolled environments): \\[Z_m = \\mu_m \\mathbf{1}_K + A_m + E_m\\] \\[A_m \\sim N(0_K, \\tau_m^2 \\Lambda)\\]\n\nRandom marker effects account for heterogeneity\nCorrelation matrices Σ and Λ estimated from data\n\nMeta-Regression Test: \\[H_0: \\{\\text{cov}(\\mu_m \\mathbf{1}_K + A_m, X) = 0\\} \\text{ vs } H_1: \\{\\text{cov}(\\mu_m \\mathbf{1}_K + A_m, X) \\neq 0\\}\\]\nTest statistic: \\(\\frac{Z_m^T X}{\\sqrt{X^T \\Sigma X}} \\sim N(0,1)\\) under H₀\n\n\nCorrelation Matrix Estimation\nTwo filtering approaches to identify H₀ markers:\n\nP-value threshold: Include markers with p_mk &gt; λ in all environments\nPosterior probability (default): Mixture model-based filtering excluding markers with P(H₁) &gt; 0.6\n\nCorrelation estimate: \\[\\hat{\\Sigma}_{k,k'} = \\text{cor}(Z_k, Z_{k'}) = \\frac{\\sum_{m \\in H_0} (Z_{mk} - \\bar{Z}_k)(Z_{mk'} - \\bar{Z}_{k'})}{\\sqrt{\\sum (Z_{mk} - \\bar{Z}_k)^2} \\sqrt{\\sum (Z_{mk'} - \\bar{Z}_{k'})^2}}\\]"
  },
  {
    "objectID": "genetics/dewalsche_2025_39792927.html#simulation-study",
    "href": "genetics/dewalsche_2025_39792927.html#simulation-study",
    "title": "metaGE: Investigating genotype x environment interactions through GWAS meta-analysis",
    "section": "Simulation Study",
    "text": "Simulation Study\n\nDesign\n\nGenotypes: 247 maize F1 hybrids, 506,460 SNPs\nEnvironments: 22 trials\nQTL types:\n\nFixed effect (constant across environments)\nCompletely random effect\nRandom effects correlated with environment similarities\n\nCovariate-dependent (proportional to Tmax, Tnight, or Psi)\n\nSimulations: 50 runs per QTL type, 12 QTLs per run\nHeritability: 0.5, QTLs explain 44% of genetic variance\n\n\n\nType I Error Control\nFDR on H₀ chromosomes (most stringent):\n\n\n\nMethod\nQTL Type\nFDR_chr\n\n\n\n\nmetaGE_FE\nFixed\n0.00\n\n\nmetaGE_RE\nRandom\n0.04\n\n\nmetaGE_RE\nRandomCov\n0.02\n\n\nmetaGE_MR\nCovariate\n0.00-0.02\n\n\nMETAL_FE\nFixed\n1.00\n\n\nMETAL_RE\nRandom/Cov\n0.88-1.00\n\n\nmash\nAll types\n0.14-0.88\n\n\n\nWhole genome FDR (5 Mb window):\n\n\n\nMethod\nRange across scenarios\n\n\n\n\nmetaGE\n0.09-0.18\n\n\nMETAL\n0.93-0.94\n\n\nmash\n0.32-0.85\n\n\n\n\n\nDetection Power\n5 Mb detection window:\n\n\n\nQTL Type\nmetaGE\nMETAL\nmash\n\n\n\n\nFixed effect\n0.09\n0.98\n0.20\n\n\nRandom effect\n0.51\n0.16\n0.79\n\n\nRandomCov\n0.26\n0.58\n0.53\n\n\nCovariate (avg)\n0.37\n0.06\n0.41\n\n\n\nDespite lower raw power than competitors, metaGE’s proper FDR control makes identified associations reliable.\nMAF effect on power (metaGE_FE): - Low MAF [0.20-0.25]: 0.04 - Medium MAF [0.30-0.35]: 0.08 - High MAF [0.40-0.45]: 0.14\n\n\nMeta-Regression Specificity\nTesting covariate-dependent QTLs:\n\n\n\nMR test\nTarget QTLs detected\nCross-detected\n\n\n\n\nTnight\n34.5% (Tnight QTLs)\n5.5% (Tmax QTLs)\n\n\nTmax\n26.5% (Tmax QTLs)\n7% (Tnight QTLs)\n\n\nPsi\n52% (Psi QTLs)\n&lt;1% (others)\n\n\n\nCross-detection correlated with environmental covariate correlation (r_Tnight-Tmax = 0.71, r_Tnight-Psi = -0.11)."
  },
  {
    "objectID": "genetics/dewalsche_2025_39792927.html#application-i-arabidopsis-competition-response",
    "href": "genetics/dewalsche_2025_39792927.html#application-i-arabidopsis-competition-response",
    "title": "metaGE: Investigating genotype x environment interactions through GWAS meta-analysis",
    "section": "Application I: Arabidopsis Competition Response",
    "text": "Application I: Arabidopsis Competition Response\n\nDataset\n\n195 accessions, 981,278 SNPs\n6 controlled micro-habitats (3 soils × competition/no competition)\nTrait: Bolting time\nCompetition: Poa annua weed in environments B, D, F\n\n\n\nResults\nmetaGE FE procedure: - 191 SNPs in 61 QTLs identified - 51/61 significant in at least one individual GWAS - Enrichment ratio = 4.13 for candidate flowering genes (q₀.₀₅ = 0.066, q₀.₉₅ = 3.2)\nComparison with METAL: - METAL: &gt;165,000 P-values &lt;0.01 (expected ~10,000 under H₀) - Declared 15% of markers significant (severe inflation)\nContrasted FE test (competition vs. no competition): - 221 SNPs in 72 QTLs with environment-specific effects - 160 candidate genes enriched for: - Development (P = 8.9×10⁻³) - Cell processes (P = 1.5×10⁻³) - Tetrapyrrole synthesis (P = 0.020) - 71/72 QTLs were novel (not detected by standard FE test)\n\n\nMajor Finding: QTL5_22.0\nLocation: Chromosome 5, AtCNGC4 genomic region - 22 markers with sign-switching effects based on competition - Positive effects without competition, negative/null with competition - AtCNGC4 known roles: - Floral transition regulation - Plant immunity impairment - Consistent with development-defense tradeoffs"
  },
  {
    "objectID": "genetics/dewalsche_2025_39792927.html#application-ii-maize-drought-response",
    "href": "genetics/dewalsche_2025_39792927.html#application-ii-maize-drought-response",
    "title": "metaGE: Investigating genotype x environment interactions through GWAS meta-analysis",
    "section": "Application II: Maize Drought Response",
    "text": "Application II: Maize Drought Response\n\nDataset\n\n244 dent maize lines (as hybrids), 602,356 SNPs\n22 environments (location × year × treatment)\nTrait: Grain yield\nEnvironmental covariates: Psi, Tmax, Tnight, Rad, VPDmax, ET0, Tnight.Fill\n\n\n\nmetaGE RE Results\n52 genomic regions identified, including:\n\n\n\nQTL\nChr\nLocal Score\nDetection status\n\n\n\n\nQTL3_120.0\n3\n38\nPreviously reported\n\n\nQTL6_20.3\n6\n415\nPreviously reported\n\n\nQTL7_41.4\n7\n18\nNovel\n\n\n\nQTL6_20.3 analysis: - Strong effects in 6 environments with severe heatwaves: - Night temperature ~22°C - Maximum temperature &gt;36°C - High evaporative demand (3.6 KPa) - All 6 environments: P-values &lt;1×10⁻⁶ - Colocalizes with 2.4 Mb presence/absence variant - Contains ABA-induced genes for water deficit response - Shows selection signatures during domestication/improvement\nQTL7_41.4 (novel): - Moderate positive effects across ~10/22 environments - Significant in only 2 individual GWAS (P &lt;0.01 in 10) - Harbors QTLs for plant growth rate and biomass under water deficit - Demonstrates power gain from meta-analysis\n\n\nMeta-Regression Results\nEvapotranspiration (ET0): 14 QTLs detected\nKey finding - QTL2_153.8 (marker AX-91538480): - Effects vary linearly from negative to positive with ET0 - Colocalizes with aquaporin eQTLs (PIP2.2, PIP2.1) - Related to water use efficiency and stomatal conductance\nNight temperature during flowering (Tnight): 21 QTLs - Main association &lt;0.6 Mb from QTL6_20.3 - Corroborates previous findings on heat stress response\nNight temperature during grain filling (Tnight.Fill): 15 QTLs\nExample - QTL9_28.6 (marker AX-91123283): - Positive effects on cool nights - Negative effects on hot nights - Dramatic effect reversal with temperature"
  },
  {
    "objectID": "genetics/dewalsche_2025_39792927.html#application-iii-multi-parent-population",
    "href": "genetics/dewalsche_2025_39792927.html#application-iii-multi-parent-population",
    "title": "metaGE: Investigating genotype x environment interactions through GWAS meta-analysis",
    "section": "Application III: Multi-Parent Population",
    "text": "Application III: Multi-Parent Population\n\nEU-NAM Flint Dataset\n\n11 biparental populations (8 analyzed)\n5,263 SNPs, double haploid lines\n4 locations: La Coruna, Roggenstein, Einbeck, Ploudaniel\nTrait: Biomass dry matter yield\n32 analyses (8 populations × 4 locations)\n\n\n\nResults\n16 QTLs identified, including: - 2 major QTLs also found in original publication (Garin et al.): - QTL1_117.6: Consistent across populations except F2 - QTL6_84.2: Ancestral allele (6 parents) with strong negative effect in TUM\n10 novel QTLs, including: - 5 QTLs with effect inversions between populations\nExample - QTL5_23.9: - Positive effect in F03802 population - Negative effect in F64 population - Suggests genetic background effects or allelic series\n3 QTLs associated with flowering time: - Flowering time is simpler trait and yield driver - Correlation with yield varies by environment (negative/null/positive)\n\n\nAdvantages Over Original Analysis\nOriginal study (Garin et al.): - Limited to 2/4 locations - Analyzed with computationally intensive mixed models\nmetaGE approach: - Included all 4 locations - Revealed 10 additional QTLs - Completed in 12 seconds vs. hours for mixed models"
  },
  {
    "objectID": "genetics/dewalsche_2025_39792927.html#application-iv-wheat-supplementary",
    "href": "genetics/dewalsche_2025_39792927.html#application-iv-wheat-supplementary",
    "title": "metaGE: Investigating genotype x environment interactions through GWAS meta-analysis",
    "section": "Application IV: Wheat (Supplementary)",
    "text": "Application IV: Wheat (Supplementary)\n\nDataset\n\n210 wheat lines, 108,410 SNPs\n16 environments (location × year × treatment)\nTrait: Grain yield\n\n\n\nKey Findings\n\nAll QTLs identified by metaGE RE were not significant in any single environment\nDemonstrates power gain for complex traits with small-effect QTLs\nHighlights importance of joint analysis for yield traits"
  },
  {
    "objectID": "genetics/dewalsche_2025_39792927.html#computational-performance",
    "href": "genetics/dewalsche_2025_39792927.html#computational-performance",
    "title": "metaGE: Investigating genotype x environment interactions through GWAS meta-analysis",
    "section": "Computational Performance",
    "text": "Computational Performance\nRuntime comparison (dataset: marker count):\n\n\n\nDataset\nEnvironments\nmetaGE\nMETAL\nmash\n\n\n\n\nSimulation (500K)\n22\n49s (31s*)\n2.6min\n16.6min\n\n\nArabidopsis (1M)\n6\n1.2min (26s*)\n2.6min\n29s\n\n\nMaize (600K)\n22\n2.25min (41s*)\n3.3min\n25.3min\n\n\nEU-NAM (6K)\n32\n12s (8s*)\n3s\n1.8min\n\n\nWheat (100K)\n16\n47s (30s*)\n22s\n3.3min\n\n\n\n*Time for correlation matrix inference (needs to be done only once)\nMemory efficiency: - Handles 10⁵-10⁶ markers efficiently - Single correlation matrix estimation per analysis - Independent processing of multiple hypotheses without re-estimation"
  },
  {
    "objectID": "genetics/dewalsche_2025_39792927.html#methodological-advantages",
    "href": "genetics/dewalsche_2025_39792927.html#methodological-advantages",
    "title": "metaGE: Investigating genotype x environment interactions through GWAS meta-analysis",
    "section": "Methodological Advantages",
    "text": "Methodological Advantages\n\nOver Classical Meta-Analysis (METAL)\nDependency handling: - METAL assumes independence between GWAS - Ignoring dependencies in MET causes severe FDR inflation (&gt;0.84) - metaGE explicitly models inter-environment correlations\nResult: METAL unusable for MET analysis due to Type I error inflation\n\n\nOver Mixture Models (mash)\nEnvironmental factors: - mash models different effect patterns but not environmental influences - Cannot incorporate environmental covariates - Limited ability to test specific biological hypotheses about GxE\nResult: mash suitable for pleiotropy but not designed for MET analysis\n\n\nOver Mixed Models\nScalability: - Mixed models computationally prohibitive for large-scale GWAS - Require raw phenotypic and genotypic data - metaGE: summary statistics only, minutes vs. hours/days\nFlexibility: - Easy addition/removal of environments - Handles missing data (monomorphic markers in subpopulations) - Supports unbalanced/incomplete designs without imputation\n\n\nComparison to Subgroup Meta-Analysis\nPrevious work (human genetics): - Subgroup MA and meta-regression developed for independent studies - Not adapted to correlated studies (MET with overlapping panels)\nmetaGE contribution: - First adaptation of these approaches to non-independent studies - Enables plant genetics applications"
  },
  {
    "objectID": "genetics/dewalsche_2025_39792927.html#novel-testing-capabilities",
    "href": "genetics/dewalsche_2025_39792927.html#novel-testing-capabilities",
    "title": "metaGE: Investigating genotype x environment interactions through GWAS meta-analysis",
    "section": "Novel Testing Capabilities",
    "text": "Novel Testing Capabilities\n\n1. Standard Association Test\nH₀: {μ_m = 0} - marker has no effect in any environment - Detects QTLs with any non-zero effect\n\n\n2. Heterogeneity Test\nH₀: {μ¹_m = μ²_m = … = μᴶ_m} - effects constant across groups - Identifies environment-dependent QTLs\n\n\n3. Contrast Test\nTests specific hypotheses about effect patterns - Example: Competition vs. no competition in Arabidopsis - Detected 71 new QTLs missed by standard test\n\n\n4. Meta-Regression\nGenome-wide scan for QTL-covariate relationships - Quantifies how QTL effects vary with environmental variables - Identifies adaptive QTLs responding to specific stresses"
  },
  {
    "objectID": "genetics/dewalsche_2025_39792927.html#biological-insights",
    "href": "genetics/dewalsche_2025_39792927.html#biological-insights",
    "title": "metaGE: Investigating genotype x environment interactions through GWAS meta-analysis",
    "section": "Biological Insights",
    "text": "Biological Insights\n\nPower Gain Through Joint Analysis\nArabidopsis AtCNGC4 region: - Not genome-wide significant in individual environments - Highly significant in joint analysis - Biological relevance confirmed (floral transition, immunity)\nMaize QTL7_41.4: - Significant in only 2/22 environments individually - Detected through meta-analysis - Contains known water deficit response QTLs\nWheat QTLs: - None significant in individual environments - Multiple QTLs detected jointly - Critical for complex yield traits\n\n\nInterpreting Effect Variability\nCompetition response (Arabidopsis): - Sign-switching effects indicate context-dependent gene function - Development-defense tradeoffs - Identifies condition-specific adaptive alleles\nHeat stress response (Maize): - QTL6_20.3 effects clustered in heatwave environments - Presence/absence variant under selection - Adaptive response to temperature stress\nCovariate-dependent effects: - Linear relationships between effects and ET0, temperature - Aquaporin-mediated water transport regulation - Plant growth sensitivity to water potential"
  },
  {
    "objectID": "genetics/dewalsche_2025_39792927.html#data-sharing-and-privacy",
    "href": "genetics/dewalsche_2025_39792927.html#data-sharing-and-privacy",
    "title": "metaGE: Investigating genotype x environment interactions through GWAS meta-analysis",
    "section": "Data Sharing and Privacy",
    "text": "Data Sharing and Privacy\n\nAdvantages of Summary Statistics\nConfidentiality: - No raw phenotypic or genotypic data required - Only effect sizes and P-values needed - Enables data sharing between private breeding programs\nParallel to human genetics: - Global Biobank Meta-analysis Initiative (2.2M participants, 24 BioBanks) - Consortium approach without individual data sharing\nPlant breeding applications: - Private companies can share GWAS results - Preserve competitive advantages - Collaborative QTL discovery\n\n\nTechnical Benefits\nUnbalanced designs: - Different markers tested per environment - Missing data due to monomorphism in subpopulations - No imputation required\nScale flexibility: - Different technologies/sequencing depths - Easy environment addition/removal - Post-hoc quality control\nMulti-parent populations: - Different marker sets per family - Handles genetic background effects - Detects allelic series and epistasis"
  },
  {
    "objectID": "genetics/dewalsche_2025_39792927.html#practical-recommendations",
    "href": "genetics/dewalsche_2025_39792927.html#practical-recommendations",
    "title": "metaGE: Investigating genotype x environment interactions through GWAS meta-analysis",
    "section": "Practical Recommendations",
    "text": "Practical Recommendations\n\nWhen to Use metaGE\nIdeal scenarios: - MET experiments with overlapping genotype panels - Need to control Type I error rate - Testing specific GxE hypotheses - Limited computational resources - Data privacy concerns\nNot recommended: - Single environment analysis (use standard GWAS) - Completely independent populations (classical MA sufficient) - Need individual-level covariate adjustments\n\n\nModel Selection\nFixed Effect (FE) model: - Controlled environments with a priori classification - Testing specific group contrasts - Example: Stress vs. control treatments\nRandom Effect (RE) model: - Uncontrolled field conditions - Unknown/complex environment relationships - Heterogeneous QTL effects expected\nMeta-Regression: - Quantitative environmental covariates available - Hypothesis about specific environmental drivers - Want to identify adaptive QTLs\n\n\nMultiple Testing Control\nLocal score approach (default): - Controls FDR while accounting for LD - Accumulates evidence across linked markers - Threshold ξ typically 3-4 - Chromosome-specific significance thresholds\nAlternative: Adaptive Benjamini-Hochberg - For low-density markers (e.g., MPP with &lt;10K SNPs) - When LD structure unknown"
  },
  {
    "objectID": "genetics/dewalsche_2025_39792927.html#implementation-details",
    "href": "genetics/dewalsche_2025_39792927.html#implementation-details",
    "title": "metaGE: Investigating genotype x environment interactions through GWAS meta-analysis",
    "section": "Implementation Details",
    "text": "Implementation Details\n\nR Package: metaGE\nAvailable on CRAN\nKey functions: - Fixed effect meta-analysis - Random effect meta-analysis\n- Contrast testing - Meta-regression - Local score multiple testing correction\nInput requirements: - Per-environment GWAS summary statistics (effects, P-values) - Marker positions - Optional: Environmental covariates\nOutputs: - Meta-analysis P-values - Estimated correlation matrices - Significant genomic regions - Effect size estimates per environment/group"
  },
  {
    "objectID": "genetics/dewalsche_2025_39792927.html#limitations-and-considerations",
    "href": "genetics/dewalsche_2025_39792927.html#limitations-and-considerations",
    "title": "metaGE: Investigating genotype x environment interactions through GWAS meta-analysis",
    "section": "Limitations and Considerations",
    "text": "Limitations and Considerations\n\nStatistical Assumptions\n\nMarker independence: Assumes unlinked markers\n\nAddressed by local score accounting for LD\n\nCorrelation matrix: Assumed common across markers\n\nReasonable for inter-environment correlations\nReduces computational burden\n\nNormal distribution: Z-scores assumed Gaussian under H₀\n\nStandard assumption in GWAS\nViolated if P-values not uniformly distributed under null\n\n\n\n\nDesign Considerations\nEnvironment classification: - FE model requires a priori grouping - Misclassification reduces power - RE model robust to classification uncertainty\nSample size: - Power increases with more environments - Individual environment sample sizes affect P-value quality - Minimum ~5-10 environments recommended\nCovariate correlation: - Meta-regression may detect QTLs correlated with related covariates - Careful interpretation needed with high covariate correlation - Consider testing multiple covariates independently"
  },
  {
    "objectID": "genetics/dewalsche_2025_39792927.html#related-concepts",
    "href": "genetics/dewalsche_2025_39792927.html#related-concepts",
    "title": "metaGE: Investigating genotype x environment interactions through GWAS meta-analysis",
    "section": "Related Concepts",
    "text": "Related Concepts\n\nMulti-environment trial (MET): Same genotypes evaluated across locations/years\nGenotype-by-environment (GxE) interaction: Differential genotypic response to environments\nZ-score: Standardized test statistic combining effect sign and P-value\nInter-environment correlation: Similarity between environments due to overlapping panels\nLocal score: LD-aware multiple testing procedure accumulating evidence\nMeta-regression: Modeling association between study-level covariates and effect sizes\nAllelic series: Multiple haplotypes at a locus with varying effects"
  },
  {
    "objectID": "genetics/ren_2023_37181332.html",
    "href": "genetics/ren_2023_37181332.html",
    "title": "Using GWAS summary data to impute traits for genotyped individuals",
    "section": "",
    "text": "PubMed: 37181332\nDOI: 10.1016/j.xhgg.2023.100197\nOverview generated by: Claude Sonnet 4.5, 26/11/2025"
  },
  {
    "objectID": "genetics/ren_2023_37181332.html#key-findings",
    "href": "genetics/ren_2023_37181332.html#key-findings",
    "title": "Using GWAS summary data to impute traits for genotyped individuals",
    "section": "Key Findings",
    "text": "Key Findings\nThis study introduces LS-imputation, a nonparametric method that uses GWAS summary statistics combined with individual-level genotypes to impute trait values, enabling nonlinear SNP-trait association analyses and machine learning applications that are impossible with summary statistics alone.\n\nMain Discoveries\n\nNovel imputation approach: First method to recover genetic components of traits from GWAS summary data for nonlinear association analysis\nPerfect recovery property: When test genotypes match training genotypes (X = X*), the method perfectly recovers (centered) trait values, capturing nonlinear SNP-trait information despite using only linear marginal associations\nSuperior performance for association analysis: LS-imputation outperforms state-of-the-art PRS method (PRS-CS) for subsequent association analyses under non-additive models and SNP-SNP interaction detection\nEnables new analyses: Makes possible three applications currently impossible with GWAS summary data: non-additive genetic models, SNP-SNP interaction detection, and nonlinear prediction models"
  },
  {
    "objectID": "genetics/ren_2023_37181332.html#study-design",
    "href": "genetics/ren_2023_37181332.html#study-design",
    "title": "Using GWAS summary data to impute traits for genotyped individuals",
    "section": "Study Design",
    "text": "Study Design\n\nCore Problem\nGWAS summary statistics measure only linear marginal SNP-trait associations, limiting their use to linear analyses. The method addresses: How to use summary data for nonlinear SNP-trait analyses?\n\n\nGenetic Model\nAssumes unspecified functional form: \\[y = E(y|x) + \\varepsilon = g(x) + \\varepsilon\\]\nwhere: - \\(g(x)\\) is the unknown genetic component (possibly nonlinear) - \\(\\varepsilon\\) captures environmental effects and noise - No parametric assumptions on \\(g(\\cdot)\\)\n\n\nMethod Overview\nInput: - GWAS summary data: \\(\\{(\\hat{\\beta}_j^*, s_j^*): j=1,\\ldots,p\\}\\) from training data \\((X^*, Y^*)\\) - Test genotype matrix: \\(X\\) (\\(n_2 \\times p\\))\nOutput: Imputed trait values \\(\\hat{Y}\\) for test individuals\nKey insight: With large samples, \\(\\hat{\\beta}^* \\approx \\hat{\\beta}\\) (both estimate same true \\(\\beta\\)), which can be used to formulate least-squares problem."
  },
  {
    "objectID": "genetics/ren_2023_37181332.html#the-ls-imputation-method",
    "href": "genetics/ren_2023_37181332.html#the-ls-imputation-method",
    "title": "Using GWAS summary data to impute traits for genotyped individuals",
    "section": "The LS-Imputation Method",
    "text": "The LS-Imputation Method\n\nFormulation\nIf \\(Y\\) were available, marginal association estimates would be: \\[\\hat{\\beta} = \\frac{1}{n_2-1}X'Y\\]\nSince \\(\\hat{\\beta}^*\\) (from training) \\(\\approx \\hat{\\beta}\\) (from test), solve:\n\\[\\hat{Y} = \\arg\\min_Y \\|\\hat{\\beta}^* - \\frac{1}{n_2-1}X'Y\\|^2\\]\nSolution: \\[\\hat{Y} = (n_2-1)(XX')^+X\\hat{\\beta}^*\\]\nwhere \\((XX')^+\\) is the Moore-Penrose generalized inverse (due to centering of SNPs).\n\n\nRegularized Implementation\nFor computational stability, use ridge regularization: \\[\\hat{Y}(\\lambda) = (n_2-1)(XX' + \\lambda I)^{-1}X\\hat{\\beta}^*\\]\nDefault: \\(\\lambda = 10^{-6}\\) (computationally fast and stable)\n\n\nBatch Processing\nFor large \\(n_2\\): - Divide test data into batches of size \\(m\\) - Apply method to each batch separately - Requires \\(p &gt; m\\) (preferably both \\(n_1\\) and \\(p\\) large) - Choose \\(m\\) giving marginal association results similar to training data"
  },
  {
    "objectID": "genetics/ren_2023_37181332.html#uk-biobank-application",
    "href": "genetics/ren_2023_37181332.html#uk-biobank-application",
    "title": "Using GWAS summary data to impute traits for genotyped individuals",
    "section": "UK Biobank Application",
    "text": "UK Biobank Application\n\nDataset\n\nTrait: HDL cholesterol\nTotal individuals: 356,351 (White British ancestry)\nSNPs: 715,783 (after QC: MAF&gt;0.05, missing&lt;10%, HWE p&gt;0.001, LD pruning r²&lt;0.8)\nSplit:\n\nTraining: \\(n_1 = 178,175\\)\nTest: \\(n_2 = 178,176\\)\n\nImplementation: 50,000 SNPs (p&lt;0.05 in training), 9 batches (8×20K + 1×18K individuals)\n\n\n\nPerfect Recovery Test\nWhen \\(X = X^*\\) (same genotypes as training): - LS-imputation: Correlation with true values = 0.999+ - PRS-CS: Correlation &lt; 0.5 (imperfect recovery)\nDemonstrates unique property: LS-imputation can perfectly recover trait values for training genotypes, capturing nonlinear information.\n\n\nTest Data Imputation Performance\nCorrelation between observed and imputed HDL:\n\n\n\nMethod\nCorrelation (unadjusted)\nCorrelation (adjusted*)\n\n\n\n\nLS-imputation\n0.177\n0.204\n\n\nPRS-CS\n0.279\n0.313\n\n\n\n*Adjusted for sex and age\nInterpretation: PRS-CS shows higher correlation (expected, as linear effects dominate heritability), but LS-imputation better preserves information for association analyses."
  },
  {
    "objectID": "genetics/ren_2023_37181332.html#application-i-non-additive-genetic-models",
    "href": "genetics/ren_2023_37181332.html#application-i-non-additive-genetic-models",
    "title": "Using GWAS summary data to impute traits for genotyped individuals",
    "section": "Application I: Non-Additive Genetic Models",
    "text": "Application I: Non-Additive Genetic Models\n\nAdditive Model Results\nComparison of significant SNPs at genome-wide threshold (\\(5\\times10^{-8}\\)):\n\n\n\n\n\n\n\n\nAnalysis\nApproach\nPerformance\n\n\n\n\nTraining (observed)\nStandard GWAS\nBaseline\n\n\nTest (observed)\nStandard GWAS\nSimilar to training\n\n\nTest (LS-imputed)\nOur method\nSimilar to observed, slightly conservative\n\n\nTest (PRS-CS-imputed)\nPRS method\nWay too many significant SNPs\n\n\n\nManhattan plot patterns: LS-imputation closely matched observed data distribution, while PRS-CS identified excessive associations (any SNP in PRS model or LD with them becomes significant).\n\n\nRecessive Model Results\nTesting SNPs under recessive genetic model:\nLS-imputation: - Distribution of significant SNPs similar to observed - Slightly more conservative (fewer false positives) - Effect size estimates highly correlated with true estimates\nPRS-CS: - Severe inflation of significant associations - Not suitable for non-additive model testing\n\n\nDominant Model Results\nSimilar pattern observed (Supplementary results): - LS-imputation: Good agreement with observed - PRS-CS: Excessive false positives\n\n\nQuantitative Comparison\nEffect size correlations (50,000 SNPs):\n\n\n\nModel\nLS vs. Observed\nPRS-CS vs. Observed\n\n\n\n\nAdditive\n0.90+\n0.40-0.60\n\n\nRecessive\n0.85+\n0.30-0.50\n\n\n\nConclusion: LS-imputation preserves information needed for non-additive model testing; PRS-CS does not."
  },
  {
    "objectID": "genetics/ren_2023_37181332.html#application-ii-snp-snp-interaction-detection",
    "href": "genetics/ren_2023_37181332.html#application-ii-snp-snp-interaction-detection",
    "title": "Using GWAS summary data to impute traits for genotyped individuals",
    "section": "Application II: SNP-SNP Interaction Detection",
    "text": "Application II: SNP-SNP Interaction Detection\n\nAnalysis Strategy\n\nIdentified 1,758 marginally significant SNPs (p&lt;10⁻⁶) in training data\nRemoved high-LD SNPs (r²&gt;0.99) → 1,652 SNPs\nTested all pairwise interactions: \\(\\binom{1652}{2} = 1,364,026\\) tests\n\nModel for each pair: \\[Y_i = \\alpha_0 + \\text{SNP}_{1i} \\times \\alpha_1 + \\text{SNP}_{2i} \\times \\alpha_2 + \\text{SNP}_{1i} \\times \\text{SNP}_{2i} \\times \\alpha_{12} + \\varepsilon_i\\]\nTest: \\(H_0: \\alpha_{12} = 0\\) (Wald test)\nSignificance threshold: \\(2.5 \\times 10^{-8}\\) (Bonferroni correction)\n\n\nResults\nInteraction effect estimates:\n\n\n\nComparison\nCorrelation\n\n\n\n\nTraining (observed) vs. Test (observed)\nBaseline\n\n\nTest (observed) vs. Test (LS-imputed)\n0.95+\n\n\nTest (observed) vs. Test (PRS-CS-imputed)\n0.60-0.70\n\n\n\nP-value correlations: Similar pattern, with LS-imputation showing strong agreement with observed data.\n\n\nSignificant Interactions Identified\nSNP-SNP pairs (Bonferroni p&lt;\\(2.5\\times10^{-8}\\)):\n\n\n\nDataset\nSignificant pairs\nAgreement with observed\n\n\n\n\nTraining (observed)\nBaseline\n-\n\n\nTest (observed)\nSimilar\nReference\n\n\nTest (LS-imputed)\nHigh overlap\n85-90%\n\n\nTest (PRS-CS-imputed)\nModerate overlap\n60-70%\n\n\n\nLocus-locus interactions: Defined using 1,703 independent LD blocks - LS-imputation: High concordance with observed - Differences between LS-imputed and observed ≤ differences between training and test (both observed)\nConclusion: LS-imputation successfully detects SNP-SNP interactions; PRS-CS less suitable."
  },
  {
    "objectID": "genetics/ren_2023_37181332.html#application-iii-nonlinear-trait-prediction",
    "href": "genetics/ren_2023_37181332.html#application-iii-nonlinear-trait-prediction",
    "title": "Using GWAS summary data to impute traits for genotyped individuals",
    "section": "Application III: Nonlinear Trait Prediction",
    "text": "Application III: Nonlinear Trait Prediction\n\nRandom Forest Setup\nTraining: 70% of test data (random subset) Validation: Remaining 30% Features: 1,652 marginally significant SNPs\nGoal: Compare RF predictions using observed vs. imputed traits for training\n\n\nResults\nCorrelation of RF predictions on validation data:\n\n\n\nTraining data\nCorrelation with true trait\n\n\n\n\nObserved traits\nBaseline\n\n\nLS-imputed traits\n0.722\n\n\nPRS-CS-imputed traits\n0.658\n\n\n\nInterpretation: LS-imputed traits retain more information about SNP-trait associations (possibly nonlinear) than PRS-CS-imputed traits.\nWhy LS-imputation performs better: - Captures nonlinear relationships in training data - No parametric model assumptions - Information borrowing across similar individuals"
  },
  {
    "objectID": "genetics/ren_2023_37181332.html#statistical-properties",
    "href": "genetics/ren_2023_37181332.html#statistical-properties",
    "title": "Using GWAS summary data to impute traits for genotyped individuals",
    "section": "Statistical Properties",
    "text": "Statistical Properties\n\nInformation Content\nFor test genotypes \\(X\\), imputed trait is: \\[\\hat{Y} \\approx \\frac{n_2-1}{n_1-1}(XX'/p)C_{n_1}Y^*\\]\nwhere: - \\(XX'/p\\) measures genotypic similarities - \\(C_{n_1} = I - 11'/n_1\\) is centering matrix - \\(Y^*\\) are training trait values\nImplication: Imputed trait is weighted average of training traits, weights determined by genotypic similarity.\n\n\nSpecial Case: Perfect Recovery\nWhen \\(X = X^*\\): \\[\\hat{Y} \\rightarrow^P C_{n_1}Y^*\\]\nAs \\(p \\rightarrow \\infty\\), imputed values converge to centered training trait values, which contain nonlinear SNP-trait information.\n\n\nVariance Properties\nFor imputed trait: \\[\\text{Var}(\\hat{Y}) = (n_2-1)^2(XX')^+X\\text{Var}(\\hat{\\beta}^*)X'(XX')^+\\]\nKey points: - Elements of \\(\\hat{Y}\\) are correlated (not iid) - Variances unequal across individuals - Practical solution: Treat as independent in subsequent analyses (simplification) - Choose appropriate batch size \\(m\\) to minimize bias-variance trade-off\n\n\nAsymptotic Behavior\nWith iid normal X (simplified case):\nSmall \\(n_2\\) (fixed): \\[\\text{Var}(\\hat{Y}_j) \\approx n_2\\tau^2/p\\]\nLarge \\(n_2\\) (with \\(n_2/p \\rightarrow c \\in (0,1)\\)): \\[\\text{Var}(\\hat{Y}_j) = n_2 O(1)\\left(\\frac{1}{n_1} + \\frac{1}{n_2}\\right)\\tau^2\\]\nRecommendation: Use smaller \\(n_2\\) (or batch size \\(m\\)) for smaller variances."
  },
  {
    "objectID": "genetics/ren_2023_37181332.html#comparison-ls-imputation-vs.-prs-cs",
    "href": "genetics/ren_2023_37181332.html#comparison-ls-imputation-vs.-prs-cs",
    "title": "Using GWAS summary data to impute traits for genotyped individuals",
    "section": "Comparison: LS-Imputation vs. PRS-CS",
    "text": "Comparison: LS-Imputation vs. PRS-CS\n\nPrediction Performance\nTrait value correlation (higher is better for prediction): - PRS-CS &gt; LS-imputation - Expected: Linear effects dominate heritability - PRS-CS optimized for prediction\n\n\nAssociation Analysis Performance\nEffect size estimation (for subsequent GWAS): - LS-imputation &gt;&gt; PRS-CS - Critical for non-additive models - Essential for interaction detection\n\n\nWhy PRS Methods Fail for Association Analysis\nPRS-CS assumptions: \\[Y = X\\beta + \\varepsilon\\] \\[\\beta \\sim \\text{ContinuousShrinkage}(\\text{prior})\\]\nProblems: 1. Assumes linear model with specific SNPs 2. Imputed traits reflect estimated linear effects only 3. Any SNP in model (or LD with them) will be “significant” by definition 4. Not suitable for testing associations\n\n\nFundamental Difference\n\n\n\nFeature\nLS-imputation\nPRS-CS\n\n\n\n\nModel\nNonparametric\nParametric linear\n\n\nCaptures nonlinearity\nYes\nNo\n\n\nPerfect recovery\nYes\nNo\n\n\nPrediction\nGood\nBetter\n\n\nAssociation analysis\nBest\nPoor\n\n\nInteraction detection\nBest\nPoor"
  },
  {
    "objectID": "genetics/ren_2023_37181332.html#implementation-details",
    "href": "genetics/ren_2023_37181332.html#implementation-details",
    "title": "Using GWAS summary data to impute traits for genotyped individuals",
    "section": "Implementation Details",
    "text": "Implementation Details\n\nComputational Considerations\nRequirements: - \\(p &gt; n_2\\) (or \\(p &gt; m\\) if batches used) - More constraints than unknowns - Unique solution (up to centering)\nMatrix inversion: - Used linalg.inv from Python numpy - Default \\(\\lambda = 10^{-6}\\) for regularization - Fast and stable computation\nMemory management: - Batch processing for large \\(n_2\\) - Typical batch: \\(m = 20,000\\) individuals - Trade-off: smaller \\(m\\) → smaller variance, but information loss between batches\n\n\nParameter Selection\nSNP number (\\(p\\)): - Larger is better (more constraints) - Example: Used 50,000 SNPs (p&lt;0.05 in training) - Can use all available (memory permitting)\nTraining sample (\\(n_1\\)): - Larger is better (more accurate \\(\\hat{\\beta}^*\\)) - Example: 178,175 individuals\nBatch size (\\(m\\)): - Choose to give marginal results similar to training - Not too large (information loss between batches) - Not too small (computational inefficiency) - Example: 20,000 individuals per batch\n\n\nQuality Control Strategy\nRecommended: Choose \\(m\\) where imputed trait gives: 1. Marginal effect estimates ≈ training estimates 2. Standard errors ≈ training SEs (after rescaling)\nSE rescaling: \\(\\sqrt{n_2/n_1} \\times SE_{test}\\) for comparison"
  },
  {
    "objectID": "genetics/ren_2023_37181332.html#extensions-and-variations",
    "href": "genetics/ren_2023_37181332.html#extensions-and-variations",
    "title": "Using GWAS summary data to impute traits for genotyped individuals",
    "section": "Extensions and Variations",
    "text": "Extensions and Variations\n\nBinary Traits\nMethod extended to binary outcomes (Supplementary): - Similar formulation - Logistic regression framework - Applied to UK Biobank hypertension data - Promising preliminary results\n\n\nWeighted Least Squares\nAlternative to ordinary least squares: \\[\\hat{Y}_{WLS} = \\arg\\min_Y (\\hat{\\beta}^* - \\frac{1}{n_2-1}X'Y)'W(\\hat{\\beta}^* - \\frac{1}{n_2-1}X'Y)\\]\nwhere \\(W\\) = diagonal matrix with weights \\(\\propto 1/\\text{Var}(\\hat{\\beta}_j^*)\\)\nResult: Similar to OLS (Supplementary), not pursued further.\n\n\nIntercept Known Case\nIf intercept \\(\\alpha_0\\) available for each SNP: - No centering needed - \\(X\\) is full rank - \\((XX')^+ = (XX')^{-1}\\) - Simpler interpretation\n\n\nSample Size Sensitivity\nTraining sample \\(n_1\\): Larger always better SNP number \\(p\\): Larger always better Test sample \\(n_2\\): Results stable for \\(n_2 \\geq 25,000\\) Batch size \\(m\\): Complex trade-off, choose empirically"
  },
  {
    "objectID": "genetics/ren_2023_37181332.html#practical-applications",
    "href": "genetics/ren_2023_37181332.html#practical-applications",
    "title": "Using GWAS summary data to impute traits for genotyped individuals",
    "section": "Practical Applications",
    "text": "Practical Applications\n\nUse Case 1: Augmenting Incomplete Data\nScenario: Biobank with genotypes but missing trait - Late-onset disease (e.g., Alzheimer’s) not yet manifested - Expensive/difficult-to-measure phenotype - Large GWAS summary data available externally\nSolution: Impute trait values to augment analyses\n\n\nUse Case 2: Cross-Study Integration\nScenario: Multiple related studies - Different traits measured - Want to analyze trait not measured in focal study - GWAS summary available from other studies\nSolution: Use summary data to impute unmeasured traits\n\n\nUse Case 3: Privacy-Preserving Collaboration\nScenario: Private breeding programs or clinical cohorts - Cannot share individual-level data - Can share summary statistics - Want to conduct joint analyses\nSolution: Each site imputes traits using others’ summaries\n\n\nUse Case 4: Nonlinear Model Development\nScenario: Develop complex prediction models - Neural networks, deep learning, gradient boosting - Require individual-level data - Only summary data available\nSolution: Impute traits to enable nonlinear model training"
  },
  {
    "objectID": "genetics/ren_2023_37181332.html#limitations-and-considerations",
    "href": "genetics/ren_2023_37181332.html#limitations-and-considerations",
    "title": "Using GWAS summary data to impute traits for genotyped individuals",
    "section": "Limitations and Considerations",
    "text": "Limitations and Considerations\n\nCurrent Limitations\n\nVariance structure: Elements of \\(\\hat{Y}\\) are correlated and have unequal variances\n\nCurrently ignored in subsequent analyses\nMay cause slight over/under-estimation of SEs\nAccounting for correlations computationally prohibitive\n\nCentering effects: Each batch centered at mean 0\n\nInformation loss between batches (relative levels)\nMitigated by using larger batches\nTrade-off with variance considerations\n\nConstraint requirement: Needs \\(p &gt; m\\)\n\nMust have more SNPs than individuals per batch\nMay limit applicability in some scenarios\n\nRare variant use: Current implementation uses common variants only\n\nRare variants have lower genotyping quality\nExpected to contain less heritability information\nCould be explored with sequencing data\n\n\n\n\nStatistical Assumptions\n\nSame population: Training and test from same population\nUnrelated individuals: No close relatives in test data\nWhite noise errors: \\(\\varepsilon\\) independent of genotypes\nLarge samples: Asymptotic properties require large \\(n_1\\), \\(p\\)\n\n\n\nInterpretation Caveats\nImputed values: - Represent genetic components only - Do not capture environmental variation - Centered (mean 0 within each batch) - Should not be treated as observed phenotypes in all contexts\nSubsequent analyses: - Slightly conservative p-values (good for Type I error control) - Effect size estimates unbiased - Power may be slightly reduced vs. observed data"
  },
  {
    "objectID": "genetics/ren_2023_37181332.html#comparison-to-alternative-approaches",
    "href": "genetics/ren_2023_37181332.html#comparison-to-alternative-approaches",
    "title": "Using GWAS summary data to impute traits for genotyped individuals",
    "section": "Comparison to Alternative Approaches",
    "text": "Comparison to Alternative Approaches\n\nvs. PRS Methods\nAll existing PRS methods for summary data: - Assume linear models - Optimize for prediction - Not designed for association analysis - Cannot detect nonlinear effects\nLS-imputation: - Nonparametric - Optimizes for association analysis - Can detect nonlinear effects - Less optimal for pure prediction\n\n\nvs. Multi-Trait Imputation\nPrevious methods (Dahl et al., Hormozdiari et al.): - Impute focal trait using other measured traits - Problem: Any variants associated with imputation traits will appear associated with focal trait - Loss of specificity\nLS-imputation: - Uses only genotypes and summary data for focal trait - Maintains specificity to focal trait - Suitable for association analysis\n\n\nvs. Direct GWAS Summary Analysis\nStandard approach with summary data: - Can only test linear marginal associations - Cannot detect non-additive effects - Cannot detect interactions - Cannot use nonlinear prediction models\nLS-imputation approach: - Enables all of the above - More flexible for exploratory analysis - Can combine with machine learning methods"
  },
  {
    "objectID": "genetics/ren_2023_37181332.html#future-directions",
    "href": "genetics/ren_2023_37181332.html#future-directions",
    "title": "Using GWAS summary data to impute traits for genotyped individuals",
    "section": "Future Directions",
    "text": "Future Directions\n\nMethodological Extensions\n\nEfficient algorithms: Handle larger datasets without batching\nGeneralized least squares: Account for correlated marginal estimates\nBetter variance estimation: Properly handle correlated imputed values\nRare variant integration: Extend to sequencing-based data\n\n\n\nAdditional Applications\n\nMulti-trait analysis: Jointly impute multiple correlated traits\nTranscriptome-wide studies: Impute gene expression for TWAS\nPolygenic score development: Use imputed traits to train complex nonlinear PRS models\nPathway analysis: Enable pathway-level nonlinear analyses\n\n\n\nPractical Improvements\n\nAutomated parameter selection: Data-driven choice of \\(m\\), \\(p\\)\nDistributed computing: Parallel batch processing\nMemory optimization: More efficient matrix operations\nQuality metrics: Better diagnostics for imputation quality"
  },
  {
    "objectID": "genetics/ren_2023_37181332.html#related-concepts",
    "href": "genetics/ren_2023_37181332.html#related-concepts",
    "title": "Using GWAS summary data to impute traits for genotyped individuals",
    "section": "Related Concepts",
    "text": "Related Concepts\n\nMoore-Penrose inverse: Generalized inverse for non-full-rank matrices\nCentering matrix: \\(C_n = I - 11'/n\\) projects to zero-mean subspace\nGenotypic similarity: Measured by \\(XX'/p\\) (normalized dot products)\nInformation borrowing: Imputed value uses data from similar individuals\nLeast squares: Optimization framework minimizing squared residuals\nRegularization: Adding penalty (ridge) for numerical stability\nBatch processing: Dividing large datasets for computational efficiency"
  }
]