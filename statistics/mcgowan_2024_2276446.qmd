---
title: "Causal Inference Is Not Just a Statistics Problem"
description: |
  * **Core Argument**: This article argues that **causal inference** relies primarily on **study design** and **domain knowledge** to establish untestable assumptions (like exchangeability and no unmeasured confounding), with statistical methods serving only to quantify the effect under those assumptions.
  * **Design Trumps Analysis**: The authors emphasize that a causal estimate is invalid if the study design fails to account for critical (especially **unmeasured**) **confounders**, regardless of the sophistication of the statistical modeling used.
  * **The Role of Causal Diagrams**: Identifying which variables to control is a **causal question**, not a statistical one, necessitating the use of **Directed Acyclic Graphs (DAGs)** and scientific expertise to avoid introducing bias by controlling for mediators or colliders.
  * **Conclusion**: Teaching and practicing causal inference requires prioritizing the **formulation of a causal question** and the **design of the study** before the application of statistical tools.
date: last-modified
categories: [assumptions, causal inference, epidemiology, statistical methods, study design]
---
**PubMed:** Not Indexed (Journal of Statistics and Data Science Education)
**DOI:** [10.1080/26939169.2023.2276446](https://doi.org/10.1080/26939169.2023.2276446)
**Overview generated by:** Gemini 2.5 Flash, 26/11/2025

## Key Findings

This article argues that **causal inference**—the process of determining whether an exposure causes an outcome—is a challenge rooted primarily in **study design and conceptual modeling**, not just statistical analysis. While statistical methods are necessary for quantifying effects, they cannot salvage a poorly designed study or validate a flawed causal hypothesis.

### Causal Inference is Not Statistical Regression

The authors emphasize the crucial distinction between **prediction/association** (a purely statistical exercise) and **causal inference** (a scientific exercise):

1.  **Causality Requires Assumptions**: Unlike association, causality requires making strong, often **untestable assumptions** about the data-generating process. These assumptions include **positivity** (everyone had a chance to receive the treatment), **consistency** (the treatment is well-defined), and **exchangeability** (the treated and untreated groups are comparable, usually requiring control for all **confounders**). 
2.  **Statistics Quantifies, Design Ensures Validity**: Statistical methods (like regression, matching, or propensity scores) can only *adjust* for observed confounding variables under the assumption that all necessary confounders have been identified and measured without error. If a critical confounder is unmeasured (**unmeasured confounding**), the resulting causal estimate is likely biased, regardless of the sophistication of the statistics used.

### The Primacy of Study Design

The article strongly aligns with the philosophy that **"Design Trumps Analysis"** (a concept attributed to Donald Rubin).

* **Need for Domain Knowledge**: The process of identifying the correct causal model and the necessary variables to control (confounders) is **a non-statistical process** that relies entirely on **domain-specific scientific knowledge** (e.g., biology, epidemiology, medicine).
* **The "Which Variables to Control?" Problem**: The decision of which covariates to include in a regression model is a **causal question**, not a statistical one. Including a variable that is actually a **collider** or a **mediator** can *introduce* bias where none existed, an error statisticians cannot prevent without external scientific guidance.
* **Randomized Controlled Trials (RCTs)**: RCTs are the gold standard for causal inference precisely because they use a **design** (randomization) to satisfy the assumption of **exchangeability** (balance all confounders, measured and unmeasured), thereby circumventing the statistical problem of controlling for confounders.

### Conclusion and Education Focus

The conclusion stresses that teaching causal inference must go beyond simply running statistical models. Students must be trained to:
* **Formulate a Causal Question** first.
* **Diagram the Causal Structure** using tools like **Directed Acyclic Graphs (DAGs)**.
* **Identify the Sources of Bias** (confounding, selection bias, measurement error) based on their domain knowledge.
* **Choose a Design** (experimental or observational) that minimizes these biases.
* **Use Statistics** only to quantify the effect size within the context of the chosen design and stated causal assumptions.