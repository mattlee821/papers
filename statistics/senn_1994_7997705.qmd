---
title: "TESTING FOR BASELINE BALANCE IN CLINICAL TRIALS"
description: |
  * **Core Principle**: This paper argues that performing **tests of baseline homogeneity** (p-value tests) in randomized controlled trials (RCTs) is **philosophically unsound, of no practical value, and potentially misleading**, as randomization ensures comparability in expectation.
  * **The Flaw**: A non-significant baseline difference does not prove balance (it reflects low power), and a significant difference is merely a chance event that does not invalidate the randomization.
  * **Recommendation**: The authors recommend that researchers must **abandon baseline testing** and, instead, identify known **prognostic variables** in the trial-plan and fit them in an **Analysis of Covariance (ANCOVA)** model regardless of their baseline p-value, which increases the **precision and power** of the final treatment effect estimate.
date: last-modified
categories: [analysis of covariance, baseline balance, bias, clinical trials, randomization, statistical methods]
---
**PubMed:** [7997705](https://pubmed.ncbi.nlm.nih.gov/7997705/)
**DOI:** [10.1002/sim.4780131610](http://dx.doi.org/10.1002/sim.4780131610)
**Overview generated by:** Gemini 2.5 Flash, 26/11/2025

## Key Findings: The Misguided Practice of Testing Baseline Balance

This influential paper by Stephen Senn critiques the common, but statistically unsound, practice in randomized controlled trials (RCTs) of performing **"tests of baseline homogeneity"** (i.e., p-value tests comparing baseline characteristics between treatment arms) before proceeding to analyze the treatment effect on the outcome. Senn argues that this practice is both philosophically flawed and practically misleading.

### The Problem with Testing for Balance

The core issue lies in the interpretation of **randomization** and the nature of the null hypothesis in a properly conducted RCT:

1.  **Philosophically Unsound**: The goal of randomization is to ensure that, in expectation, the treatment groups are comparable. Any observed differences at baseline are due purely to **chance**, and no statistical test is required to confirm this. Performing a test is equivalent to testing the effectiveness of a coin tossâ€”a pointless exercise.
2.  **No Practical Value**: A statistically significant difference at baseline (e.g., $p < 0.05$ for age difference) does **not** indicate a flaw in the randomization process; it is merely a low-probability chance event that is expected to occur in 5% of all covariates tested. Such a finding offers no useful guidance on how to analyze the treatment effect.
3.  **Potentially Misleading**:
    * **Non-significant difference ($p > 0.05$):** This does not prove the groups are "balanced" or comparable. It only means the study lacked the power to detect a difference, or that the observed difference was not large enough to cross the arbitrary significance threshold. The non-significant result might wrongly convince the investigator that no adjustment is needed, even if the difference is clinically important.
    * **Significant difference ($p < 0.05$):** This may wrongly prompt an investigator to use an *ad hoc* adjustment (like Analysis of Covariance, ANCOVA) only for that specific variable, introducing subjectivity into the analysis plan and potentially invalidating the comparison of treatment effects.

### The Recommended Practice: Analysis of Covariance (ANCOVA)

Senn strongly recommends replacing baseline balance testing with a principled approach to analysis:

* **Pre-specify Prognostic Variables**: The study protocol should identify and list all known or suspected **prognostic covariates** (variables predictive of the outcome), regardless of their baseline distribution.
* **Routine ANCOVA**: These prognostic variables should be included in the primary analysis model using **Analysis of Covariance (ANCOVA)**, irrespective of their p-value from the baseline comparison. 
* **Statistical Advantages**: Adjusting for important prognostic variables using ANCOVA increases the **precision** and **statistical power** of the treatment effect estimate, leading to narrower confidence intervals. Crucially, the validity of ANCOVA in an RCT relies on the fact that randomization *ensures* the baseline covariates are unrelated to the treatment assignment, not on their baseline p-value.

### Conclusion

The paper concludes that the practice of baseline testing is a confusion of philosophy and statistics. Researchers should focus on **design** (randomization) to ensure validity and **statistical efficiency** (ANCOVA) to maximize power, rather than using post-randomization tests that are incapable of fulfilling the purpose for which they are intended.